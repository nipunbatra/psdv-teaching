<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Nipun Batra">
<meta name="dcterms.date" content="2025-04-14">

<title>Principal Component Analysis – PSDV Teaching Resources</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-234273d1456647dabc34a594ac50e507.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-b87cffa2dfe7192c47c0a1d12e778cd4.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../figures/pexels-solodsha-9009923.jpg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">PSDV Resources</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../notebooks.html"> 
<span class="menu-text">Notebooks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../slides.html"> 
<span class="menu-text">Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../questions.html"> 
<span class="menu-text">Questions</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/nipunbatra/psdv-teaching"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://nipunbatra.github.io/psdv25/"> 
<span class="menu-text">Course 2025</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://nipunbatra.github.io"> 
<span class="menu-text">Instructor</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks/pca.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../notebooks/pca.html">Principal Component Analysis</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Getting Started</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Probability and Statistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/set.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Set</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability Theory Fundamentals</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/random-variables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/pmf-discrete.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability Mass Functions and Common Discrete Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/pdf-continuous.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability Density Functions and Continuous Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/cdf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Cumulative Distribution Functions and Inverse Sampling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/cdf-discrete.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CDF for Discrete Random Variables</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Core Concepts</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/expectation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Mathematical Expectation and Law of Large Numbers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/iid.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Independent and Identically Distributed (i.i.d) Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/law-large-numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Law of Large Numbers and Central Limit Theorem</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/2d-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Distributions in 2D</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/joint-distribution-properties.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Joint Distribution Properties</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/sum-random-vars.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sum of Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/random-vector.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random Vector</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/pca.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Principal Component Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/logistic-regression-generative.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">PMF and their applications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/embeddings-angle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Embeddings and Vector Angles</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Data Science Tools</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/intro-numpy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to NumPy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/introduction-pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Pandas</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/introduction-matplotlib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Matplotlib</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Interactive &amp; Quizzes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/widgets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interactive Data Exploration with Jupyter Widgets</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/quiz1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Analysis Quiz - Pandas GroupBy Operations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/images-joint-distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Images and Joint Distributions</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#principal-component-analysis-pca-theory-and-applications" id="toc-principal-component-analysis-pca-theory-and-applications" class="nav-link active" data-scroll-target="#principal-component-analysis-pca-theory-and-applications">Principal Component Analysis (PCA): Theory and Applications</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link" data-scroll-target="#learning-objectives">Learning Objectives</a></li>
  <li><a href="#theoretical-background" id="toc-theoretical-background" class="nav-link" data-scroll-target="#theoretical-background">Theoretical Background</a>
  <ul class="collapse">
  <li><a href="#the-variance-maximization-problem" id="toc-the-variance-maximization-problem" class="nav-link" data-scroll-target="#the-variance-maximization-problem">The Variance Maximization Problem</a></li>
  <li><a href="#mathematical-derivation" id="toc-mathematical-derivation" class="nav-link" data-scroll-target="#mathematical-derivation">Mathematical Derivation</a></li>
  <li><a href="#key-results" id="toc-key-results" class="nav-link" data-scroll-target="#key-results">Key Results</a></li>
  <li><a href="#properties-of-pca" id="toc-properties-of-pca" class="nav-link" data-scroll-target="#properties-of-pca">Properties of PCA</a></li>
  </ul></li>
  <li><a href="#implementation-from-first-principles" id="toc-implementation-from-first-principles" class="nav-link" data-scroll-target="#implementation-from-first-principles">Implementation from First Principles</a></li>
  <li><a href="#example-1-understanding-pca-with-2d-correlated-data" id="toc-example-1-understanding-pca-with-2d-correlated-data" class="nav-link" data-scroll-target="#example-1-understanding-pca-with-2d-correlated-data">Example 1: Understanding PCA with 2D Correlated Data</a>
  <ul class="collapse">
  <li><a href="#understanding-the-data-generation-process" id="toc-understanding-the-data-generation-process" class="nav-link" data-scroll-target="#understanding-the-data-generation-process">Understanding the Data Generation Process</a></li>
  <li><a href="#step-1-data-centering" id="toc-step-1-data-centering" class="nav-link" data-scroll-target="#step-1-data-centering">Step 1: Data Centering</a></li>
  <li><a href="#step-2-computing-the-covariance-matrix" id="toc-step-2-computing-the-covariance-matrix" class="nav-link" data-scroll-target="#step-2-computing-the-covariance-matrix">Step 2: Computing the Covariance Matrix</a></li>
  <li><a href="#step-3-eigenvalue-decomposition" id="toc-step-3-eigenvalue-decomposition" class="nav-link" data-scroll-target="#step-3-eigenvalue-decomposition">Step 3: Eigenvalue Decomposition</a></li>
  <li><a href="#step-4-projection-and-reconstruction" id="toc-step-4-projection-and-reconstruction" class="nav-link" data-scroll-target="#step-4-projection-and-reconstruction">Step 4: Projection and Reconstruction</a></li>
  </ul></li>
  <li><a href="#example-2-pca-on-high-dimensional-data-mnist" id="toc-example-2-pca-on-high-dimensional-data-mnist" class="nav-link" data-scroll-target="#example-2-pca-on-high-dimensional-data-mnist">Example 2: PCA on High-Dimensional Data (MNIST)</a>
  <ul class="collapse">
  <li><a href="#data-preprocessing-and-centering" id="toc-data-preprocessing-and-centering" class="nav-link" data-scroll-target="#data-preprocessing-and-centering">Data Preprocessing and Centering</a></li>
  <li><a href="#understanding-the-covariance-structure" id="toc-understanding-the-covariance-structure" class="nav-link" data-scroll-target="#understanding-the-covariance-structure">Understanding the Covariance Structure</a></li>
  <li><a href="#comprehensive-pca-analysis-with-visualizations" id="toc-comprehensive-pca-analysis-with-visualizations" class="nav-link" data-scroll-target="#comprehensive-pca-analysis-with-visualizations">Comprehensive PCA Analysis with Visualizations</a></li>
  <li><a href="#principal-components-as-eigendigits" id="toc-principal-components-as-eigendigits" class="nav-link" data-scroll-target="#principal-components-as-eigendigits">Principal Components as ‘Eigendigits’</a></li>
  <li><a href="#dimensionality-reduction-and-reconstruction-quality" id="toc-dimensionality-reduction-and-reconstruction-quality" class="nav-link" data-scroll-target="#dimensionality-reduction-and-reconstruction-quality">Dimensionality Reduction and Reconstruction Quality</a></li>
  </ul></li>
  <li><a href="#summary-and-key-takeaways" id="toc-summary-and-key-takeaways" class="nav-link" data-scroll-target="#summary-and-key-takeaways">Summary and Key Takeaways</a>
  <ul class="collapse">
  <li><a href="#mathematical-foundations" id="toc-mathematical-foundations" class="nav-link" data-scroll-target="#mathematical-foundations">Mathematical Foundations:</a></li>
  <li><a href="#practical-insights" id="toc-practical-insights" class="nav-link" data-scroll-target="#practical-insights">Practical Insights:</a></li>
  <li><a href="#key-properties" id="toc-key-properties" class="nav-link" data-scroll-target="#key-properties">Key Properties:</a></li>
  <li><a href="#applications-and-extensions" id="toc-applications-and-extensions" class="nav-link" data-scroll-target="#applications-and-extensions">Applications and Extensions:</a></li>
  <li><a href="#when-to-use-pca" id="toc-when-to-use-pca" class="nav-link" data-scroll-target="#when-to-use-pca">When to Use PCA:</a></li>
  <li><a href="#best-practices" id="toc-best-practices" class="nav-link" data-scroll-target="#best-practices">Best Practices:</a></li>
  <li><a href="#center-the-data" id="toc-center-the-data" class="nav-link" data-scroll-target="#center-the-data">Center the data</a></li>
  <li><a href="#finding-covariance" id="toc-finding-covariance" class="nav-link" data-scroll-target="#finding-covariance">Finding covariance</a></li>
  </ul></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.dev/nipunbatra/psdv-teaching/blob/main/notebooks/pca.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/nipunbatra/psdv-teaching/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks/pca.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../notebooks/pca.html">Principal Component Analysis</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Principal Component Analysis</h1>
  <div class="quarto-categories">
    <div class="quarto-category">ML</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Nipun Batra </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 14, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div id="cell-1" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="bu">print</span>(np.__version__)</span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> torch </span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-6"><a href="#cb1-6"></a></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co"># Retina mode</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="op">%</span>config InlineBackend.figure_format <span class="op">=</span> <span class="st">'retina'</span></span>
<span id="cb1-11"><a href="#cb1-11"></a></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.26.4</code></pre>
</div>
</div>
<section id="principal-component-analysis-pca-theory-and-applications" class="level1">
<h1>Principal Component Analysis (PCA): Theory and Applications</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Principal Component Analysis (PCA) is one of the most fundamental techniques in data science and machine learning. It serves as a cornerstone for dimensionality reduction, data visualization, and understanding the structure of high-dimensional datasets. PCA transforms data to a lower-dimensional space while preserving as much variance (information) as possible.</p>
<p>At its core, PCA answers a crucial question: “What are the most important directions of variation in my data?” This question is essential when dealing with high-dimensional data where visualization is challenging, storage is expensive, or computational complexity is prohibitive.</p>
<p>PCA has applications across numerous fields: - <strong>Data Visualization</strong>: Reducing high-dimensional data to 2D/3D for plotting - <strong>Data Compression</strong>: Storing data more efficiently with minimal information loss - <strong>Noise Reduction</strong>: Filtering out noise by keeping only major components - <strong>Feature Engineering</strong>: Creating new features that capture data structure - <strong>Exploratory Data Analysis</strong>: Understanding patterns and relationships in data</p>
</section>
<section id="learning-objectives" class="level2">
<h2 class="anchored" data-anchor-id="learning-objectives">Learning Objectives</h2>
<p>By the end of this notebook, you will be able to:</p>
<ol type="1">
<li><strong>Understand</strong> the mathematical foundations of PCA and eigenvalue decomposition</li>
<li><strong>Derive</strong> the PCA algorithm from variance maximization principles</li>
<li><strong>Implement</strong> PCA from scratch using eigendecomposition</li>
<li><strong>Interpret</strong> principal components as directions of maximum variance</li>
<li><strong>Analyze</strong> the trade-off between dimensionality reduction and information retention</li>
<li><strong>Apply</strong> PCA to real-world datasets (synthetic and MNIST)</li>
<li><strong>Evaluate</strong> PCA results using reconstruction error and explained variance</li>
<li><strong>Connect</strong> PCA to linear algebra concepts (covariance, eigenvectors, projections)</li>
</ol>
</section>
<section id="theoretical-background" class="level2">
<h2 class="anchored" data-anchor-id="theoretical-background">Theoretical Background</h2>
<section id="the-variance-maximization-problem" class="level3">
<h3 class="anchored" data-anchor-id="the-variance-maximization-problem">The Variance Maximization Problem</h3>
<p>PCA finds the directions in which data varies the most. Mathematically, given data matrix <span class="math inline">\(X \in \mathbb{R}^{n \times p}\)</span> (n samples, p features), we want to find a unit vector <span class="math inline">\(v \in \mathbb{R}^p\)</span> such that the variance of the projected data <span class="math inline">\(Xv\)</span> is maximized.</p>
<p><strong>Optimization Problem:</strong> <span class="math display">\[\max_{v} \text{Var}(Xv) \quad \text{subject to} \quad ||v|| = 1\]</span></p>
</section>
<section id="mathematical-derivation" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-derivation">Mathematical Derivation</h3>
<p>For centered data (mean-subtracted), the variance of projected data is: <span class="math display">\[\text{Var}(Xv) = \frac{1}{n-1} ||Xv||^2 = \frac{1}{n-1} v^T X^T X v = v^T \Sigma v\]</span></p>
<p>where <span class="math inline">\(\Sigma = \frac{1}{n-1} X^T X\)</span> is the sample covariance matrix.</p>
<p><strong>Lagrangian Solution:</strong> <span class="math display">\[L = v^T \Sigma v - \lambda (v^T v - 1)\]</span></p>
<p>Taking derivatives and setting to zero: <span class="math display">\[\frac{\partial L}{\partial v} = 2\Sigma v - 2\lambda v = 0\]</span></p>
<p>This gives us the <strong>eigenvalue equation</strong>: <span class="math display">\[\Sigma v = \lambda v\]</span></p>
</section>
<section id="key-results" class="level3">
<h3 class="anchored" data-anchor-id="key-results">Key Results</h3>
<ol type="1">
<li><strong>Principal Components</strong>: Eigenvectors of the covariance matrix</li>
<li><strong>Explained Variance</strong>: Eigenvalues represent variance along each principal component</li>
<li><strong>Optimal Projection</strong>: PCA provides the best linear dimensionality reduction in terms of preserved variance</li>
</ol>
</section>
<section id="properties-of-pca" class="level3">
<h3 class="anchored" data-anchor-id="properties-of-pca">Properties of PCA</h3>
<ul>
<li><strong>Orthogonal Components</strong>: Principal components are mutually orthogonal</li>
<li><strong>Decreasing Variance</strong>: Components are ordered by decreasing eigenvalues</li>
<li><strong>Linear Transformation</strong>: PCA is a linear transformation of the original data</li>
<li><strong>Reversible</strong>: Can reconstruct original data (with some loss if dimensions are reduced)</li>
</ul>
<hr>
</section>
</section>
<section id="implementation-from-first-principles" class="level2">
<h2 class="anchored" data-anchor-id="implementation-from-first-principles">Implementation from First Principles</h2>
</section>
<section id="example-1-understanding-pca-with-2d-correlated-data" class="level2">
<h2 class="anchored" data-anchor-id="example-1-understanding-pca-with-2d-correlated-data">Example 1: Understanding PCA with 2D Correlated Data</h2>
<p>Let’s start with a simple 2D example to build intuition about what PCA does.</p>
<section id="understanding-the-data-generation-process" class="level3">
<h3 class="anchored" data-anchor-id="understanding-the-data-generation-process">Understanding the Data Generation Process</h3>
<p>We’re generating data from a <strong>multivariate normal distribution</strong> with: - <strong>Mean</strong>: <span class="math inline">\(\mu = [5, -2]\)</span> - <strong>Covariance</strong>: <span class="math inline">\(\Sigma = \begin{bmatrix} 1.0 &amp; 0.7 \\ 0.7 &amp; 1.0 \end{bmatrix}\)</span></p>
<p>The correlation coefficient is 0.7, meaning the variables are positively correlated. This creates an elliptical data cloud tilted along the correlation direction.</p>
</section>
<section id="step-1-data-centering" class="level3">
<h3 class="anchored" data-anchor-id="step-1-data-centering">Step 1: Data Centering</h3>
<p><strong>Why center the data?</strong> PCA finds directions of maximum variance from the origin. If data isn’t centered, the first principal component might just point toward the data mean rather than capturing the true variance structure.</p>
<p><strong>Interpretation:</strong> - <strong>Original data</strong>: Centered around [5, -2] with elliptical spread - <strong>Centered data</strong>: Now centered at origin [0, 0], preserving the variance structure - <strong>Red point</strong>: Original mean, <strong>Blue point</strong>: Centered mean (at origin)</p>
<p>Centering doesn’t change the relative positions of data points, just shifts the entire dataset.</p>
</section>
<section id="step-2-computing-the-covariance-matrix" class="level3">
<h3 class="anchored" data-anchor-id="step-2-computing-the-covariance-matrix">Step 2: Computing the Covariance Matrix</h3>
<p>The covariance matrix captures how variables co-vary. For centered data:</p>
<p><span class="math display">\[\Sigma = \frac{1}{n-1} X^T X\]</span></p>
<p>where each element <span class="math inline">\(\Sigma_{ij} = \text{Cov}(X_i, X_j)\)</span>.</p>
<p><strong>Understanding the Covariance Matrix:</strong> - <strong>Diagonal elements</strong>: Variances of individual variables - <strong>Off-diagonal elements</strong>: Covariances between variables - <strong>Positive covariance (0.729)</strong>: Variables tend to increase/decrease together - <strong>Nearly symmetric</strong>: <span class="math inline">\(\text{Cov}(X_1, X_2) = \text{Cov}(X_2, X_1)\)</span></p>
</section>
<section id="step-3-eigenvalue-decomposition" class="level3">
<h3 class="anchored" data-anchor-id="step-3-eigenvalue-decomposition">Step 3: Eigenvalue Decomposition</h3>
<p>The heart of PCA lies in decomposing the covariance matrix:</p>
<p><span class="math display">\[\Sigma v = \lambda v\]</span></p>
<p><strong>Physical Interpretation:</strong> - <strong>Eigenvectors (v)</strong>: Directions of principal axes - <strong>Eigenvalues (λ)</strong>: Amount of variance along each principal axis</p>
<p><strong>Key Insights:</strong></p>
<ol type="1">
<li><strong>First Principal Component (PC1)</strong>:
<ul>
<li>Direction: [0.695, 0.719] (roughly 45° angle, pointing up-right)</li>
<li>Variance: 1.78 (captures most variation)</li>
<li>This aligns with the major axis of the elliptical data cloud</li>
</ul></li>
<li><strong>Second Principal Component (PC2)</strong>:
<ul>
<li>Direction: [-0.719, 0.695] (perpendicular to PC1)</li>
<li>Variance: 0.32 (captures remaining variation)</li>
<li>This aligns with the minor axis of the ellipse</li>
</ul></li>
<li><strong>Orthogonality</strong>: PC1 and PC2 are perpendicular (dot product ≈ 0)</li>
</ol>
<p>The eigenvectors show us the natural coordinate system of our data!</p>
</section>
<section id="step-4-projection-and-reconstruction" class="level3">
<h3 class="anchored" data-anchor-id="step-4-projection-and-reconstruction">Step 4: Projection and Reconstruction</h3>
<p><strong>Projection</strong>: Transform data to principal component space <span class="math display">\[Y = X_{\text{centered}} V\]</span></p>
<p><strong>Reconstruction</strong>: Transform back to original space <span class="math display">\[X_{\text{reconstructed}} = Y V^T\]</span></p>
<p>For 1D PCA, we only use the first principal component:</p>
<p><strong>Understanding the Results:</strong></p>
<ol type="1">
<li><p><strong>Projection Formula</strong>: <span class="math inline">\(y_i = \mathbf{x}_i^T \mathbf{v}_1\)</span> (dot product of data point with first eigenvector)</p></li>
<li><p><strong>Reconstruction Formula</strong>: <span class="math inline">\(\hat{\mathbf{x}}_i = y_i \mathbf{v}_1\)</span> (scale the eigenvector by the projection)</p></li>
<li><p><strong>Geometric Interpretation</strong>: Each point is projected onto the line defined by the first principal component, then reconstructed back to 2D space</p></li>
<li><p><strong>Information Loss</strong>: The distance between original and reconstructed points represents lost information (captured by PC2)</p></li>
</ol>
<p>The reconstruction shows how well a 1D representation captures the 2D data structure!</p>
<div id="cell-13" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># Simple 2D blobs with say 0.7 correlation</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>X <span class="op">=</span> torch.distributions.multivariate_normal.MultivariateNormal(</span>
<span id="cb3-3"><a href="#cb3-3"></a>    torch.tensor([<span class="fl">5.0</span>, <span class="op">-</span><span class="fl">2.0</span>]), torch.tensor([[<span class="fl">1.0</span>, <span class="fl">0.7</span>], [<span class="fl">0.7</span>, <span class="fl">1.0</span>]])</span>
<span id="cb3-4"><a href="#cb3-4"></a>).sample((<span class="dv">1000</span>,))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-14" class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># Comprehensive PCA visualization</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">12</span>))</span>
<span id="cb4-3"><a href="#cb4-3"></a></span>
<span id="cb4-4"><a href="#cb4-4"></a><span class="co"># 1. Original vs Centered Data</span></span>
<span id="cb4-5"><a href="#cb4-5"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">30</span>, label<span class="op">=</span><span class="st">'Original Data'</span>)</span>
<span id="cb4-6"><a href="#cb4-6"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].scatter(X_mean[<span class="dv">0</span>, <span class="dv">0</span>], X_mean[<span class="dv">0</span>, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, s<span class="op">=</span><span class="dv">100</span>, marker<span class="op">=</span><span class="st">'x'</span>, </span>
<span id="cb4-7"><a href="#cb4-7"></a>                  linewidth<span class="op">=</span><span class="dv">3</span>, label<span class="op">=</span><span class="st">'Original Mean'</span>)</span>
<span id="cb4-8"><a href="#cb4-8"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].scatter(X_centered[:, <span class="dv">0</span>], X_centered[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">30</span>, </span>
<span id="cb4-9"><a href="#cb4-9"></a>                  color<span class="op">=</span><span class="st">'orange'</span>, label<span class="op">=</span><span class="st">'Centered Data'</span>)</span>
<span id="cb4-10"><a href="#cb4-10"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].scatter(<span class="dv">0</span>, <span class="dv">0</span>, color<span class="op">=</span><span class="st">'blue'</span>, s<span class="op">=</span><span class="dv">100</span>, marker<span class="op">=</span><span class="st">'x'</span>, linewidth<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb4-11"><a href="#cb4-11"></a>                  label<span class="op">=</span><span class="st">'Centered Mean'</span>)</span>
<span id="cb4-12"><a href="#cb4-12"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Data Centering'</span>)</span>
<span id="cb4-13"><a href="#cb4-13"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].legend()</span>
<span id="cb4-14"><a href="#cb4-14"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb4-15"><a href="#cb4-15"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].axis(<span class="st">'equal'</span>)</span>
<span id="cb4-16"><a href="#cb4-16"></a></span>
<span id="cb4-17"><a href="#cb4-17"></a><span class="co"># 2. Covariance Matrix Visualization</span></span>
<span id="cb4-18"><a href="#cb4-18"></a>im <span class="op">=</span> axes[<span class="dv">0</span>, <span class="dv">1</span>].imshow(cov.numpy(), cmap<span class="op">=</span><span class="st">'coolwarm'</span>, vmin<span class="op">=-</span><span class="dv">1</span>, vmax<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-19"><a href="#cb4-19"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'Covariance Matrix'</span>)</span>
<span id="cb4-20"><a href="#cb4-20"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb4-21"><a href="#cb4-21"></a>    <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb4-22"><a href="#cb4-22"></a>        axes[<span class="dv">0</span>, <span class="dv">1</span>].text(j, i, <span class="ss">f'</span><span class="sc">{</span>cov[i,j]<span class="sc">:.3f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'center'</span>, </span>
<span id="cb4-23"><a href="#cb4-23"></a>                       fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb4-24"><a href="#cb4-24"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_xticks([<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb4-25"><a href="#cb4-25"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_yticks([<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb4-26"><a href="#cb4-26"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_xticklabels([<span class="st">'X1'</span>, <span class="st">'X2'</span>])</span>
<span id="cb4-27"><a href="#cb4-27"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_yticklabels([<span class="st">'X1'</span>, <span class="st">'X2'</span>])</span>
<span id="cb4-28"><a href="#cb4-28"></a>plt.colorbar(im, ax<span class="op">=</span>axes[<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb4-29"><a href="#cb4-29"></a></span>
<span id="cb4-30"><a href="#cb4-30"></a><span class="co"># 3. Eigendecomposition Results</span></span>
<span id="cb4-31"><a href="#cb4-31"></a>axes[<span class="dv">0</span>, <span class="dv">2</span>].bar([<span class="st">'PC1'</span>, <span class="st">'PC2'</span>], eigvals.numpy(), alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span>[<span class="st">'blue'</span>, <span class="st">'red'</span>])</span>
<span id="cb4-32"><a href="#cb4-32"></a>axes[<span class="dv">0</span>, <span class="dv">2</span>].set_title(<span class="st">'Eigenvalues (Explained Variance)'</span>)</span>
<span id="cb4-33"><a href="#cb4-33"></a>axes[<span class="dv">0</span>, <span class="dv">2</span>].set_ylabel(<span class="st">'Variance'</span>)</span>
<span id="cb4-34"><a href="#cb4-34"></a><span class="cf">for</span> i, val <span class="kw">in</span> <span class="bu">enumerate</span>(eigvals.numpy()):</span>
<span id="cb4-35"><a href="#cb4-35"></a>    axes[<span class="dv">0</span>, <span class="dv">2</span>].text(i, val <span class="op">+</span> <span class="fl">0.02</span>, <span class="ss">f'</span><span class="sc">{</span>val<span class="sc">:.3f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb4-36"><a href="#cb4-36"></a>axes[<span class="dv">0</span>, <span class="dv">2</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb4-37"><a href="#cb4-37"></a></span>
<span id="cb4-38"><a href="#cb4-38"></a><span class="co"># 4. Principal Components Visualization</span></span>
<span id="cb4-39"><a href="#cb4-39"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].scatter(X_centered[:, <span class="dv">0</span>], X_centered[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">'lightblue'</span>)</span>
<span id="cb4-40"><a href="#cb4-40"></a></span>
<span id="cb4-41"><a href="#cb4-41"></a><span class="co"># Plot eigenvectors as arrows from origin</span></span>
<span id="cb4-42"><a href="#cb4-42"></a>scale <span class="op">=</span> <span class="dv">2</span>  <span class="co"># Scale for visibility</span></span>
<span id="cb4-43"><a href="#cb4-43"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb4-44"><a href="#cb4-44"></a>    vec <span class="op">=</span> eigvecs[:, i] <span class="op">*</span> scale</span>
<span id="cb4-45"><a href="#cb4-45"></a>    axes[<span class="dv">1</span>, <span class="dv">0</span>].arrow(<span class="dv">0</span>, <span class="dv">0</span>, vec[<span class="dv">0</span>], vec[<span class="dv">1</span>], head_width<span class="op">=</span><span class="fl">0.1</span>, head_length<span class="op">=</span><span class="fl">0.1</span>, </span>
<span id="cb4-46"><a href="#cb4-46"></a>                    fc<span class="op">=</span><span class="ss">f'C</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>, ec<span class="op">=</span><span class="ss">f'C</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span>, linewidth<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb4-47"><a href="#cb4-47"></a>                    label<span class="op">=</span><span class="ss">f'PC</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> (λ=</span><span class="sc">{</span>eigvals[i]<span class="sc">:.3f}</span><span class="ss">)'</span>)</span>
<span id="cb4-48"><a href="#cb4-48"></a></span>
<span id="cb4-49"><a href="#cb4-49"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].set_title(<span class="st">'Principal Components</span><span class="ch">\n</span><span class="st">(Eigenvectors)'</span>)</span>
<span id="cb4-50"><a href="#cb4-50"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].legend()</span>
<span id="cb4-51"><a href="#cb4-51"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb4-52"><a href="#cb4-52"></a>axes[<span class="dv">1</span>, <span class="dv">0</span>].axis(<span class="st">'equal'</span>)</span>
<span id="cb4-53"><a href="#cb4-53"></a></span>
<span id="cb4-54"><a href="#cb4-54"></a><span class="co"># 5. 1D Projection</span></span>
<span id="cb4-55"><a href="#cb4-55"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].scatter(X_proj_1d[:, <span class="dv">0</span>], X_proj_1d[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.8</span>, s<span class="op">=</span><span class="dv">30</span>, </span>
<span id="cb4-56"><a href="#cb4-56"></a>                  color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'1D Projection'</span>)</span>
<span id="cb4-57"><a href="#cb4-57"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].scatter(X_centered[:, <span class="dv">0</span>], X_centered[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">20</span>, </span>
<span id="cb4-58"><a href="#cb4-58"></a>                  color<span class="op">=</span><span class="st">'lightblue'</span>, label<span class="op">=</span><span class="st">'Original Data'</span>)</span>
<span id="cb4-59"><a href="#cb4-59"></a></span>
<span id="cb4-60"><a href="#cb4-60"></a><span class="co"># Draw projection lines</span></span>
<span id="cb4-61"><a href="#cb4-61"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(X_centered), <span class="dv">20</span>):  <span class="co"># Show every 20th line for clarity</span></span>
<span id="cb4-62"><a href="#cb4-62"></a>    x_orig <span class="op">=</span> X_centered[i]</span>
<span id="cb4-63"><a href="#cb4-63"></a>    x_proj <span class="op">=</span> X_proj_1d[i]</span>
<span id="cb4-64"><a href="#cb4-64"></a>    axes[<span class="dv">1</span>, <span class="dv">1</span>].plot([x_orig[<span class="dv">0</span>], x_proj[<span class="dv">0</span>]], [x_orig[<span class="dv">1</span>], x_proj[<span class="dv">1</span>]], </span>
<span id="cb4-65"><a href="#cb4-65"></a>                   <span class="st">'k--'</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb4-66"><a href="#cb4-66"></a></span>
<span id="cb4-67"><a href="#cb4-67"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].set_title(<span class="st">'1D PCA Reconstruction'</span>)</span>
<span id="cb4-68"><a href="#cb4-68"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].legend()</span>
<span id="cb4-69"><a href="#cb4-69"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb4-70"><a href="#cb4-70"></a>axes[<span class="dv">1</span>, <span class="dv">1</span>].axis(<span class="st">'equal'</span>)</span>
<span id="cb4-71"><a href="#cb4-71"></a></span>
<span id="cb4-72"><a href="#cb4-72"></a><span class="co"># 6. Explained Variance Analysis</span></span>
<span id="cb4-73"><a href="#cb4-73"></a>explained_var_ratio <span class="op">=</span> eigvals <span class="op">/</span> torch.<span class="bu">sum</span>(eigvals)</span>
<span id="cb4-74"><a href="#cb4-74"></a>cumulative_var <span class="op">=</span> torch.cumsum(explained_var_ratio, dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-75"><a href="#cb4-75"></a></span>
<span id="cb4-76"><a href="#cb4-76"></a>x_pos <span class="op">=</span> np.arange(<span class="bu">len</span>(eigvals))</span>
<span id="cb4-77"><a href="#cb4-77"></a>bars <span class="op">=</span> axes[<span class="dv">1</span>, <span class="dv">2</span>].bar(x_pos, explained_var_ratio.numpy(), alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'Individual'</span>)</span>
<span id="cb4-78"><a href="#cb4-78"></a>axes[<span class="dv">1</span>, <span class="dv">2</span>].plot(x_pos, cumulative_var.numpy(), <span class="st">'ro-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, markersize<span class="op">=</span><span class="dv">8</span>, label<span class="op">=</span><span class="st">'Cumulative'</span>)</span>
<span id="cb4-79"><a href="#cb4-79"></a></span>
<span id="cb4-80"><a href="#cb4-80"></a>axes[<span class="dv">1</span>, <span class="dv">2</span>].set_title(<span class="st">'Explained Variance Ratio'</span>)</span>
<span id="cb4-81"><a href="#cb4-81"></a>axes[<span class="dv">1</span>, <span class="dv">2</span>].set_xlabel(<span class="st">'Principal Component'</span>)</span>
<span id="cb4-82"><a href="#cb4-82"></a>axes[<span class="dv">1</span>, <span class="dv">2</span>].set_ylabel(<span class="st">'Proportion of Variance'</span>)</span>
<span id="cb4-83"><a href="#cb4-83"></a>axes[<span class="dv">1</span>, <span class="dv">2</span>].set_xticks(x_pos)</span>
<span id="cb4-84"><a href="#cb4-84"></a>axes[<span class="dv">1</span>, <span class="dv">2</span>].set_xticklabels([<span class="st">'PC1'</span>, <span class="st">'PC2'</span>])</span>
<span id="cb4-85"><a href="#cb4-85"></a>axes[<span class="dv">1</span>, <span class="dv">2</span>].legend()</span>
<span id="cb4-86"><a href="#cb4-86"></a>axes[<span class="dv">1</span>, <span class="dv">2</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb4-87"><a href="#cb4-87"></a></span>
<span id="cb4-88"><a href="#cb4-88"></a><span class="co"># Add percentage labels</span></span>
<span id="cb4-89"><a href="#cb4-89"></a><span class="cf">for</span> i, (ind, cum) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(explained_var_ratio.numpy(), cumulative_var.numpy())):</span>
<span id="cb4-90"><a href="#cb4-90"></a>    axes[<span class="dv">1</span>, <span class="dv">2</span>].text(i, ind <span class="op">+</span> <span class="fl">0.02</span>, <span class="ss">f'</span><span class="sc">{</span>ind<span class="sc">:.1%}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb4-91"><a href="#cb4-91"></a>    axes[<span class="dv">1</span>, <span class="dv">2</span>].text(i, cum <span class="op">+</span> <span class="fl">0.02</span>, <span class="ss">f'</span><span class="sc">{</span>cum<span class="sc">:.1%}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb4-92"><a href="#cb4-92"></a></span>
<span id="cb4-93"><a href="#cb4-93"></a>plt.tight_layout()</span>
<span id="cb4-94"><a href="#cb4-94"></a>plt.show()</span>
<span id="cb4-95"><a href="#cb4-95"></a></span>
<span id="cb4-96"><a href="#cb4-96"></a><span class="co"># Detailed Analysis</span></span>
<span id="cb4-97"><a href="#cb4-97"></a><span class="bu">print</span>(<span class="st">"COMPREHENSIVE PCA ANALYSIS:"</span>)</span>
<span id="cb4-98"><a href="#cb4-98"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb4-99"><a href="#cb4-99"></a></span>
<span id="cb4-100"><a href="#cb4-100"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">1. DATA CHARACTERISTICS:"</span>)</span>
<span id="cb4-101"><a href="#cb4-101"></a><span class="bu">print</span>(<span class="ss">f"   - Original mean: [</span><span class="sc">{</span>X_mean[<span class="dv">0</span>, <span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>X_mean[<span class="dv">0</span>, <span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">]"</span>)</span>
<span id="cb4-102"><a href="#cb4-102"></a><span class="bu">print</span>(<span class="ss">f"   - Data shape: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-103"><a href="#cb4-103"></a><span class="bu">print</span>(<span class="ss">f"   - Correlation: </span><span class="sc">{</span>cov[<span class="dv">0</span>,<span class="dv">1</span>] <span class="op">/</span> torch<span class="sc">.</span>sqrt(cov[<span class="dv">0</span>,<span class="dv">0</span>] <span class="op">*</span> cov[<span class="dv">1</span>,<span class="dv">1</span>])<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb4-104"><a href="#cb4-104"></a></span>
<span id="cb4-105"><a href="#cb4-105"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">2. COVARIANCE MATRIX:"</span>)</span>
<span id="cb4-106"><a href="#cb4-106"></a><span class="bu">print</span>(<span class="ss">f"   - Var(X1): </span><span class="sc">{</span>cov[<span class="dv">0</span>,<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb4-107"><a href="#cb4-107"></a><span class="bu">print</span>(<span class="ss">f"   - Var(X2): </span><span class="sc">{</span>cov[<span class="dv">1</span>,<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb4-108"><a href="#cb4-108"></a><span class="bu">print</span>(<span class="ss">f"   - Cov(X1,X2): </span><span class="sc">{</span>cov[<span class="dv">0</span>,<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb4-109"><a href="#cb4-109"></a><span class="bu">print</span>(<span class="ss">f"   - Total variance: </span><span class="sc">{</span>torch<span class="sc">.</span>trace(cov)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb4-110"><a href="#cb4-110"></a></span>
<span id="cb4-111"><a href="#cb4-111"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">3. EIGENDECOMPOSITION:"</span>)</span>
<span id="cb4-112"><a href="#cb4-112"></a><span class="bu">print</span>(<span class="ss">f"   - Eigenvalues: </span><span class="sc">{</span>eigvals<span class="sc">.</span>numpy()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-113"><a href="#cb4-113"></a><span class="bu">print</span>(<span class="ss">f"   - PC1 direction: [</span><span class="sc">{</span>eigvecs[<span class="dv">0</span>,<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>eigvecs[<span class="dv">1</span>,<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">]"</span>)</span>
<span id="cb4-114"><a href="#cb4-114"></a><span class="bu">print</span>(<span class="ss">f"   - PC2 direction: [</span><span class="sc">{</span>eigvecs[<span class="dv">0</span>,<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>eigvecs[<span class="dv">1</span>,<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss">]"</span>)</span>
<span id="cb4-115"><a href="#cb4-115"></a><span class="bu">print</span>(<span class="ss">f"   - Orthogonality check: </span><span class="sc">{</span>torch<span class="sc">.</span>dot(eigvecs[:,<span class="dv">0</span>], eigvecs[:,<span class="dv">1</span>])<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb4-116"><a href="#cb4-116"></a></span>
<span id="cb4-117"><a href="#cb4-117"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">4. VARIANCE EXPLANATION:"</span>)</span>
<span id="cb4-118"><a href="#cb4-118"></a><span class="bu">print</span>(<span class="ss">f"   - PC1 explains: </span><span class="sc">{</span>explained_var_ratio[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss"> of variance"</span>)</span>
<span id="cb4-119"><a href="#cb4-119"></a><span class="bu">print</span>(<span class="ss">f"   - PC2 explains: </span><span class="sc">{</span>explained_var_ratio[<span class="dv">1</span>]<span class="sc">:.1%}</span><span class="ss"> of variance"</span>)</span>
<span id="cb4-120"><a href="#cb4-120"></a><span class="bu">print</span>(<span class="ss">f"   - Total explained: </span><span class="sc">{</span>cumulative_var[<span class="op">-</span><span class="dv">1</span>]<span class="sc">:.1%}</span><span class="ss">"</span>)</span>
<span id="cb4-121"><a href="#cb4-121"></a></span>
<span id="cb4-122"><a href="#cb4-122"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">5. RECONSTRUCTION QUALITY:"</span>)</span>
<span id="cb4-123"><a href="#cb4-123"></a>reconstruction_error <span class="op">=</span> torch.mean((X_centered <span class="op">-</span> X_proj_1d)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb4-124"><a href="#cb4-124"></a><span class="bu">print</span>(<span class="ss">f"   - Mean Squared Error (1D): </span><span class="sc">{</span>reconstruction_error<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb4-125"><a href="#cb4-125"></a><span class="bu">print</span>(<span class="ss">f"   - Variance retained (1D): </span><span class="sc">{</span>explained_var_ratio[<span class="dv">0</span>]<span class="sc">:.1%}</span><span class="ss">"</span>)</span>
<span id="cb4-126"><a href="#cb4-126"></a><span class="bu">print</span>(<span class="ss">f"   - Information lost (1D): </span><span class="sc">{</span>explained_var_ratio[<span class="dv">1</span>]<span class="sc">:.1%}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="example-2-pca-on-high-dimensional-data-mnist" class="level2">
<h2 class="anchored" data-anchor-id="example-2-pca-on-high-dimensional-data-mnist">Example 2: PCA on High-Dimensional Data (MNIST)</h2>
<p>Now let’s apply PCA to a real-world high-dimensional dataset: handwritten digits from MNIST. This demonstrates PCA’s power in reducing dimensionality while preserving essential information.</p>
<p><strong>Understanding MNIST in PCA Context:</strong></p>
<ul>
<li><strong>Original Dimensionality</strong>: 784 dimensions (28×28 pixels)</li>
<li><strong>Sample Size</strong>: 1000 images (subset for computational efficiency)</li>
<li><strong>Challenge</strong>: How can we capture the essence of digit shapes in far fewer dimensions?</li>
<li><strong>PCA Goal</strong>: Find the most important ‘pixel patterns’ that distinguish different digits</li>
</ul>
<section id="data-preprocessing-and-centering" class="level3">
<h3 class="anchored" data-anchor-id="data-preprocessing-and-centering">Data Preprocessing and Centering</h3>
</section>
<section id="understanding-the-covariance-structure" class="level3">
<h3 class="anchored" data-anchor-id="understanding-the-covariance-structure">Understanding the Covariance Structure</h3>
<p><strong>Interpreting the Covariance Matrix:</strong></p>
<ul>
<li><strong>Size</strong>: 784×784 matrix showing how each pixel correlates with every other pixel</li>
<li><strong>Patterns</strong>:
<ul>
<li>Bright regions show high correlation (pixels that tend to be bright/dark together)</li>
<li>Block-like structure suggests spatial correlations (nearby pixels are related)</li>
<li>The pattern reveals the underlying structure of how digit pixels co-vary</li>
</ul></li>
</ul>
</section>
<section id="comprehensive-pca-analysis-with-visualizations" class="level3">
<h3 class="anchored" data-anchor-id="comprehensive-pca-analysis-with-visualizations">Comprehensive PCA Analysis with Visualizations</h3>
<p>Let’s create a complete visualization showing all aspects of PCA:</p>
<div id="cell-21" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="co">### Plot the data</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb5-3"><a href="#cb5-3"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>],  alpha<span class="op">=</span><span class="fl">0.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pca_files/figure-html/cell-5-output-1.png" width="360" height="351" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="principal-components-as-eigendigits" class="level3">
<h3 class="anchored" data-anchor-id="principal-components-as-eigendigits">Principal Components as ‘Eigendigits’</h3>
<p>The principal components can be interpreted as fundamental ‘building blocks’ or ‘eigendigits’ - basic patterns that combine to form all digit images.</p>
<p><strong>Understanding Principal Components:</strong></p>
<p>Each principal component represents a different pattern of pixel variations:</p>
<ul>
<li><strong>PC1</strong>: Captures the most common variation (average brightness vs.&nbsp;background)</li>
<li><strong>PC2-PC4</strong>: Capture shape variations (edges, curves, strokes)</li>
<li><strong>Higher PCs</strong>: Capture more subtle details and noise</li>
</ul>
<p>These components are like ‘visual features’ that the human visual system might use to recognize digits!</p>
</section>
<section id="dimensionality-reduction-and-reconstruction-quality" class="level3">
<h3 class="anchored" data-anchor-id="dimensionality-reduction-and-reconstruction-quality">Dimensionality Reduction and Reconstruction Quality</h3>
<p><strong>Key Observations:</strong></p>
<ol type="1">
<li><p><strong>Dramatic Dimensionality Reduction</strong>: Even 10 components (1.3% of original dimensions) capture recognizable digit structure</p></li>
<li><p><strong>Quality vs.&nbsp;Compression Trade-off</strong>:</p>
<ul>
<li>2 components: ~25% variance, basic shape visible</li>
<li>10 components: ~60% variance, clearly recognizable digits</li>
<li>50 components: ~85% variance, high-quality reconstruction</li>
</ul></li>
<li><p><strong>Diminishing Returns</strong>: Adding more components improves quality, but with decreasing benefit</p></li>
<li><p><strong>Storage Efficiency</strong>: Instead of storing 784 values per image, we can store just 10-50 principal component coefficients!</p></li>
</ol>
<hr>
</section>
</section>
<section id="summary-and-key-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="summary-and-key-takeaways">Summary and Key Takeaways</h2>
<section id="mathematical-foundations" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-foundations">Mathematical Foundations:</h3>
<ol type="1">
<li><p><strong>Core Principle</strong>: PCA finds orthogonal directions of maximum variance through eigendecomposition of the covariance matrix</p></li>
<li><p><strong>Optimization</strong>: Solves <span class="math inline">\(\max_v v^T \Sigma v\)</span> subject to <span class="math inline">\(||v|| = 1\)</span>, yielding <span class="math inline">\(\Sigma v = \lambda v\)</span></p></li>
<li><p><strong>Geometric Interpretation</strong>: Rotates coordinate system to align with natural axes of data variation</p></li>
</ol>
</section>
<section id="practical-insights" class="level3">
<h3 class="anchored" data-anchor-id="practical-insights">Practical Insights:</h3>
<ol type="1">
<li><strong>Dimensionality Reduction</strong>: Often 90%+ of variance captured by small fraction of dimensions</li>
<li><strong>Data Compression</strong>: Store only principal component coefficients instead of raw features<br>
</li>
<li><strong>Noise Reduction</strong>: Lower components often represent noise; keeping top components filters this out</li>
<li><strong>Feature Engineering</strong>: PC scores can serve as new features for machine learning</li>
</ol>
</section>
<section id="key-properties" class="level3">
<h3 class="anchored" data-anchor-id="key-properties">Key Properties:</h3>
<ul>
<li><strong>Linear Transformation</strong>: <span class="math inline">\(Y = XW\)</span> where W contains eigenvectors</li>
<li><strong>Orthogonal Components</strong>: Principal components are uncorrelated</li>
<li><strong>Variance Ordering</strong>: Components ordered by decreasing explained variance</li>
<li><strong>Reconstruction</strong>: <span class="math inline">\(\hat{X} = YW^T\)</span> (perfect if all components kept)</li>
</ul>
</section>
<section id="applications-and-extensions" class="level3">
<h3 class="anchored" data-anchor-id="applications-and-extensions">Applications and Extensions:</h3>
<p><strong>Direct Applications:</strong> - Data visualization (reduce to 2D/3D) - Image compression and denoising - Exploratory data analysis - Preprocessing for machine learning</p>
<p><strong>Connections to Other Methods:</strong> - <strong>Factor Analysis</strong>: PCA without noise assumptions - <strong>Independent Component Analysis (ICA)</strong>: Non-orthogonal components - <strong>t-SNE/UMAP</strong>: Nonlinear dimensionality reduction - <strong>Autoencoders</strong>: Neural network-based dimensionality reduction</p>
</section>
<section id="when-to-use-pca" class="level3">
<h3 class="anchored" data-anchor-id="when-to-use-pca">When to Use PCA:</h3>
<p><strong>Good Cases:</strong> - High-dimensional data with linear correlations - Need for interpretable dimensions - Data visualization requirements - Computational efficiency important</p>
<p><strong>Limitations:</strong> - Assumes linear relationships - Components may not be interpretable - Sensitive to scaling of features - May not preserve local structure</p>
</section>
<section id="best-practices" class="level3">
<h3 class="anchored" data-anchor-id="best-practices">Best Practices:</h3>
<ol type="1">
<li><strong>Always center data</strong> (subtract mean)</li>
<li><strong>Consider scaling</strong> features if different units</li>
<li><strong>Choose components</strong> based on explained variance and domain knowledge</li>
<li><strong>Validate reconstruction quality</strong> for your specific use case</li>
<li><strong>Compare with other dimensionality reduction</strong> methods</li>
</ol>
<p>Understanding PCA provides a solid foundation for advanced topics in machine learning, computer vision, and data science. It bridges linear algebra theory with practical data analysis, making it an essential tool in the data scientist’s toolkit.</p>
</section>
<section id="center-the-data" class="level3">
<h3 class="anchored" data-anchor-id="center-the-data">Center the data</h3>
<div id="cell-28" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>X_mean <span class="op">=</span> X.mean(<span class="dv">0</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-2"><a href="#cb6-2"></a>X_centered <span class="op">=</span> X <span class="op">-</span> X_mean</span>
<span id="cb6-3"><a href="#cb6-3"></a></span>
<span id="cb6-4"><a href="#cb6-4"></a>plt.scatter(X_centered[:, <span class="dv">0</span>], X_centered[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Centered'</span>)</span>
<span id="cb6-5"><a href="#cb6-5"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.5</span>, label<span class="op">=</span><span class="st">'Original'</span>)</span>
<span id="cb6-6"><a href="#cb6-6"></a>plt.scatter(X_mean[:, <span class="dv">0</span>], X_mean[:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Original Mean'</span>)</span>
<span id="cb6-7"><a href="#cb6-7"></a>plt.scatter(X_centered.mean(<span class="dv">0</span>, keepdim<span class="op">=</span><span class="va">True</span>)[:, <span class="dv">0</span>], X_centered.mean(<span class="dv">0</span>, keepdim<span class="op">=</span><span class="va">True</span>)[:, <span class="dv">1</span>], color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'Centered Mean'</span>)</span>
<span id="cb6-8"><a href="#cb6-8"></a>plt.title(<span class="st">'Centered vs Original'</span>)</span>
<span id="cb6-9"><a href="#cb6-9"></a>plt.xlabel(<span class="st">'X1'</span>)</span>
<span id="cb6-10"><a href="#cb6-10"></a>plt.ylabel(<span class="st">'X2'</span>)</span>
<span id="cb6-11"><a href="#cb6-11"></a>plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pca_files/figure-html/cell-6-output-1.png" width="565" height="454" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="finding-covariance" class="level3">
<h3 class="anchored" data-anchor-id="finding-covariance">Finding covariance</h3>
<div id="cell-30" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>cov <span class="op">=</span> X_centered.T <span class="op">@</span> X_centered <span class="op">/</span> (X.shape[<span class="dv">0</span>] <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="bu">print</span>(<span class="st">'Covariance matrix:'</span>)</span>
<span id="cb7-3"><a href="#cb7-3"></a><span class="bu">print</span>(cov)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Covariance matrix:
tensor([[1.0229, 0.7291],
        [0.7291, 1.0733]])</code></pre>
</div>
</div>
<div id="cell-31" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="co">### Finding the eigenvalues and eigenvectors</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>eigvals, eigvecs <span class="op">=</span> torch.linalg.eigh(cov)</span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="bu">print</span>(<span class="st">'Eigenvalues:'</span>)</span>
<span id="cb9-4"><a href="#cb9-4"></a><span class="bu">print</span>(eigvals)</span>
<span id="cb9-5"><a href="#cb9-5"></a><span class="bu">print</span>(<span class="st">'Eigenvectors:'</span>)</span>
<span id="cb9-6"><a href="#cb9-6"></a><span class="bu">print</span>(eigvecs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Eigenvalues:
tensor([0.3186, 1.7776])
Eigenvectors:
tensor([[-0.7192,  0.6948],
        [ 0.6948,  0.7192]])</code></pre>
</div>
</div>
<div id="cell-32" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="co"># Plot centered data with eigenvectors</span></span>
<span id="cb11-2"><a href="#cb11-2"></a>plt.scatter(X_centered[:, <span class="dv">0</span>], X_centered[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb11-3"><a href="#cb11-3"></a></span>
<span id="cb11-4"><a href="#cb11-4"></a><span class="co"># Plot eigenvectors starting from the mean</span></span>
<span id="cb11-5"><a href="#cb11-5"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb11-6"><a href="#cb11-6"></a>    vec <span class="op">=</span> eigvecs[:, i]</span>
<span id="cb11-7"><a href="#cb11-7"></a>    plt.quiver(<span class="dv">0</span>, <span class="dv">0</span>, vec[<span class="dv">0</span>], vec[<span class="dv">1</span>], scale<span class="op">=</span><span class="dv">3</span>, color<span class="op">=</span><span class="ss">f"C</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>, label<span class="op">=</span><span class="ss">f"u</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>eigvals[i]<span class="sc">:.2f}</span><span class="ss">)"</span>)</span>
<span id="cb11-8"><a href="#cb11-8"></a></span>
<span id="cb11-9"><a href="#cb11-9"></a>plt.axis(<span class="st">'equal'</span>)</span>
<span id="cb11-10"><a href="#cb11-10"></a>plt.legend()</span>
<span id="cb11-11"><a href="#cb11-11"></a>plt.title(<span class="st">"Centered Data with Principal Directions"</span>)</span>
<span id="cb11-12"><a href="#cb11-12"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pca_files/figure-html/cell-9-output-1.png" width="546" height="434" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-33" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>top_vec <span class="op">=</span> eigvecs[:, <span class="op">-</span><span class="dv">1</span>]  <span class="co"># Last column of eigvecs (the top eigenvector)</span></span>
<span id="cb12-2"><a href="#cb12-2"></a><span class="bu">print</span>(<span class="st">'Top eigenvector:'</span>)</span>
<span id="cb12-3"><a href="#cb12-3"></a><span class="bu">print</span>(top_vec)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top eigenvector:
tensor([0.6948, 0.7192])</code></pre>
</div>
</div>
<div id="cell-34" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a><span class="co"># Project centered data onto the top eigenvector using dot product</span></span>
<span id="cb14-2"><a href="#cb14-2"></a>X_proj <span class="op">=</span> torch.zeros_like(X_centered)  <span class="co"># Initialize an empty tensor to store projections</span></span>
<span id="cb14-3"><a href="#cb14-3"></a></span>
<span id="cb14-4"><a href="#cb14-4"></a><span class="co"># Loop through each data point and project it onto the top eigenvector</span></span>
<span id="cb14-5"><a href="#cb14-5"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(X_centered.shape[<span class="dv">0</span>]):</span>
<span id="cb14-6"><a href="#cb14-6"></a>    <span class="co"># Calculate the projection of the i-th data point onto the top eigenvector</span></span>
<span id="cb14-7"><a href="#cb14-7"></a>    X_proj[i] <span class="op">=</span> torch.dot(X_centered[i], top_vec) <span class="op">*</span> top_vec  <span class="co"># Scalar projection * eigenvector</span></span>
<span id="cb14-8"><a href="#cb14-8"></a></span>
<span id="cb14-9"><a href="#cb14-9"></a><span class="co"># Reconstruct the data by adding the mean back</span></span>
<span id="cb14-10"><a href="#cb14-10"></a>X_recon <span class="op">=</span> X_proj <span class="op">+</span> X_mean</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-35" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a>X_recon</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([[ 2.8117, -4.2273],
        [ 4.4202, -2.5621],
        [ 5.5191, -1.4246],
        ...,
        [ 4.1834, -2.8073],
        [ 3.9091, -3.0913],
        [ 5.5841, -1.3573]])</code></pre>
</div>
</div>
<div id="cell-36" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.2</span>, label<span class="op">=</span><span class="st">'Original'</span>)</span>
<span id="cb17-2"><a href="#cb17-2"></a>plt.scatter(X_recon[:, <span class="dv">0</span>], X_recon[:, <span class="dv">1</span>], alpha<span class="op">=</span><span class="fl">0.8</span>, label<span class="op">=</span><span class="st">'PCA-1D'</span>)</span>
<span id="cb17-3"><a href="#cb17-3"></a>plt.axis(<span class="st">'equal'</span>)</span>
<span id="cb17-4"><a href="#cb17-4"></a>plt.legend()</span>
<span id="cb17-5"><a href="#cb17-5"></a>plt.title(<span class="st">"PCA projection onto top component"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>Text(0.5, 1.0, 'PCA projection onto top component')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pca_files/figure-html/cell-13-output-2.png" width="546" height="434" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-37" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a><span class="co"># Load MNIST dataset</span></span>
<span id="cb19-2"><a href="#cb19-2"></a><span class="im">import</span> torchvision</span>
<span id="cb19-3"><a href="#cb19-3"></a>transform <span class="op">=</span> transforms.Compose([transforms.ToTensor(), transforms.Lambda(<span class="kw">lambda</span> x: x.view(<span class="op">-</span><span class="dv">1</span>))])</span>
<span id="cb19-4"><a href="#cb19-4"></a>train_data <span class="op">=</span> torchvision.datasets.MNIST(root<span class="op">=</span><span class="st">'~/.data'</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb19-5"><a href="#cb19-5"></a></span>
<span id="cb19-6"><a href="#cb19-6"></a><span class="co"># Take a small subset of data for simplicity</span></span>
<span id="cb19-7"><a href="#cb19-7"></a>X <span class="op">=</span> train_data.data[:<span class="dv">1000</span>].<span class="bu">float</span>()  <span class="co"># Take the first 1000 images (28x28 pixels)</span></span>
<span id="cb19-8"><a href="#cb19-8"></a>y <span class="op">=</span> train_data.targets[:<span class="dv">1000</span>]  <span class="co"># Corresponding labels</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-38" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a><span class="co"># View the first image</span></span>
<span id="cb20-2"><a href="#cb20-2"></a>plt.imshow(X[<span class="dv">0</span>].reshape(<span class="dv">28</span>, <span class="dv">28</span>), cmap<span class="op">=</span><span class="st">'gray'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pca_files/figure-html/cell-15-output-1.png" width="417" height="413" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-39" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a>X <span class="op">=</span> X <span class="op">/</span> <span class="fl">255.0</span>  <span class="co"># Normalize to [0, 1]</span></span>
<span id="cb21-2"><a href="#cb21-2"></a>X_centered <span class="op">=</span> X <span class="op">-</span> X.mean(dim<span class="op">=</span><span class="dv">0</span>)  <span class="co"># Center the data by subtracting the mean</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-40" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a>X_vecs <span class="op">=</span> X_centered.reshape(X_centered.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>)  <span class="co"># Reshape to (n_samples, n_features)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-41" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a><span class="co"># Compute covariance matrix</span></span>
<span id="cb23-2"><a href="#cb23-2"></a>cov_matrix <span class="op">=</span> torch.cov(X_vecs.T)  <span class="co"># Transpose to get (n_features, n_samples)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-42" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a><span class="bu">print</span>(<span class="st">'Covariance matrix shape:'</span>, cov_matrix.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Covariance matrix shape: torch.Size([784, 784])</code></pre>
</div>
</div>
<div id="cell-43" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a>plt.imshow(cov_matrix, cmap<span class="op">=</span><span class="st">'hot'</span>, interpolation<span class="op">=</span><span class="st">'nearest'</span>)</span>
<span id="cb26-2"><a href="#cb26-2"></a>plt.colorbar()</span>
<span id="cb26-3"><a href="#cb26-3"></a>plt.title(<span class="st">'Covariance Matrix'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>Text(0.5, 1.0, 'Covariance Matrix')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pca_files/figure-html/cell-20-output-2.png" width="521" height="434" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-44" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a><span class="co"># Eigenvalue decomposition</span></span>
<span id="cb28-2"><a href="#cb28-2"></a>eigvals, eigvecs <span class="op">=</span> torch.linalg.eigh(cov_matrix)</span>
<span id="cb28-3"><a href="#cb28-3"></a><span class="bu">print</span>(<span class="st">'Eigenvalues shape:'</span>, eigvals.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Eigenvalues shape: torch.Size([784])</code></pre>
</div>
</div>
<div id="cell-45" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a><span class="co"># Top K eigenvalues and eigenvectors</span></span>
<span id="cb30-2"><a href="#cb30-2"></a>K <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb30-3"><a href="#cb30-3"></a>top_k_eigvals, top_k_indices <span class="op">=</span> torch.topk(eigvals, K)</span>
<span id="cb30-4"><a href="#cb30-4"></a>top_k_eigvecs <span class="op">=</span> eigvecs[:, top_k_indices]</span>
<span id="cb30-5"><a href="#cb30-5"></a><span class="bu">print</span>(<span class="st">'Top K eigenvalues:'</span>, top_k_eigvals)</span>
<span id="cb30-6"><a href="#cb30-6"></a><span class="bu">print</span>(<span class="st">'Top K eigenvectors shape:'</span>, top_k_eigvecs.shape)</span>
<span id="cb30-7"><a href="#cb30-7"></a><span class="co"># Plot the top K eigenvalues</span></span>
<span id="cb30-8"><a href="#cb30-8"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">4</span>))</span>
<span id="cb30-9"><a href="#cb30-9"></a>plt.bar(<span class="bu">range</span>(K), top_k_eigvals.numpy())</span>
<span id="cb30-10"><a href="#cb30-10"></a>plt.xlabel(<span class="st">'Eigenvalue Index'</span>)</span>
<span id="cb30-11"><a href="#cb30-11"></a>plt.ylabel(<span class="st">'Eigenvalue'</span>)</span>
<span id="cb30-12"><a href="#cb30-12"></a>plt.title(<span class="st">'Top K Eigenvalues'</span>)</span>
<span id="cb30-13"><a href="#cb30-13"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top K eigenvalues: tensor([5.1288, 4.0052, 3.5313, 2.8018, 2.5156, 2.3427, 1.8130, 1.5647, 1.4760,
        1.1167])
Top K eigenvectors shape: torch.Size([784, 10])</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pca_files/figure-html/cell-22-output-2.png" width="678" height="392" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-46" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1"></a><span class="co"># Project data onto the top K eigenvectors</span></span>
<span id="cb32-2"><a href="#cb32-2"></a>X_proj <span class="op">=</span> torch.matmul(X_vecs, top_k_eigvecs)</span>
<span id="cb32-3"><a href="#cb32-3"></a><span class="bu">print</span>(<span class="st">'Projected data shape:'</span>, X_proj.shape)</span>
<span id="cb32-4"><a href="#cb32-4"></a><span class="co"># Reconstruct the data from the top K components</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Projected data shape: torch.Size([1000, 10])</code></pre>
</div>
</div>
<div id="cell-47" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1"></a><span class="im">import</span> matplotlib.cm <span class="im">as</span> cm</span>
<span id="cb34-2"><a href="#cb34-2"></a></span>
<span id="cb34-3"><a href="#cb34-3"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>))</span>
<span id="cb34-4"><a href="#cb34-4"></a></span>
<span id="cb34-5"><a href="#cb34-5"></a>colors <span class="op">=</span> cm.tab10(np.arange(<span class="dv">10</span>))  <span class="co"># 10 distinct colors</span></span>
<span id="cb34-6"><a href="#cb34-6"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb34-7"><a href="#cb34-7"></a>    idx <span class="op">=</span> (y <span class="op">==</span> i)</span>
<span id="cb34-8"><a href="#cb34-8"></a>    plt.scatter(X_proj[idx, <span class="dv">0</span>], X_proj[idx, <span class="dv">1</span>], </span>
<span id="cb34-9"><a href="#cb34-9"></a>                alpha<span class="op">=</span><span class="fl">0.6</span>, color<span class="op">=</span>colors[i], label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb34-10"><a href="#cb34-10"></a></span>
<span id="cb34-11"><a href="#cb34-11"></a>plt.title(<span class="st">'PCA Projection onto Top 2 Components (MNIST)'</span>)</span>
<span id="cb34-12"><a href="#cb34-12"></a>plt.xlabel(<span class="st">'Principal Component 1'</span>)</span>
<span id="cb34-13"><a href="#cb34-13"></a>plt.ylabel(<span class="st">'Principal Component 2'</span>)</span>
<span id="cb34-14"><a href="#cb34-14"></a>plt.axis(<span class="st">'equal'</span>)</span>
<span id="cb34-15"><a href="#cb34-15"></a>plt.legend(title<span class="op">=</span><span class="st">'Digit'</span>, bbox_to_anchor<span class="op">=</span>(<span class="fl">1.05</span>, <span class="dv">1</span>), loc<span class="op">=</span><span class="st">'upper left'</span>)</span>
<span id="cb34-16"><a href="#cb34-16"></a>plt.tight_layout()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="pca_files/figure-html/cell-24-output-1.png" width="487" height="488" class="figure-img"></p>
</figure>
</div>
</div>
</div>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/nipunbatra\.github\.io\/psdv-teaching");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2024-2025, Prof.&nbsp;Nipun Batra, IIT Gandhinagar</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.dev/nipunbatra/psdv-teaching/blob/main/notebooks/pca.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/nipunbatra/psdv-teaching/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/nipunbatra/psdv-teaching">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://nipunbatra.github.io">
      <i class="bi bi-globe" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>