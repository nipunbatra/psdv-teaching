<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Nipun Batra">
<meta name="dcterms.date" content="2025-02-11">

<title>PMF and their applications – PSDV Teaching Resources</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet" class="quarto-color-scheme-extra">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-18d8b755c270e74bdd954da6158d0ad1.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-fb9de656fd51071e35b698e91f52d13a.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-18d8b755c270e74bdd954da6158d0ad1.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar docked nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../figures/pexels-solodsha-9009923.jpg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">PSDV Resources</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../notebooks.html"> 
<span class="menu-text">Notebooks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../slides.html"> 
<span class="menu-text">Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../questions.html"> 
<span class="menu-text">Questions</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/nipunbatra/psdv-teaching"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://nipunbatra.github.io/psdv25/"> 
<span class="menu-text">Course 2025</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://nipunbatra.github.io"> 
<span class="menu-text">Instructor</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks/pca.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../notebooks/logistic-regression-generative.html">PMF and their applications</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Getting Started</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Probability and Statistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/set.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Set</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability Theory Fundamentals</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/random-variables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/pmf-discrete.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability Mass Functions and Common Discrete Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/pdf-continuous.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability Density Functions and Continuous Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/cdf.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Cumulative Distribution Functions and Inverse Sampling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/cdf-discrete.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CDF for Discrete Random Variables</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Core Concepts</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/expectation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Mathematical Expectation and Law of Large Numbers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/iid.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Independent and Identically Distributed (i.i.d) Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/law-large-numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Law of Large Numbers and Central Limit Theorem</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/2d-distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Distributions in 2D</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/joint-distribution-properties.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Joint Distribution Properties</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/sum-random-vars.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sum of Random Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/random-vector.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Random Vector</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/pca.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Principal Component Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/logistic-regression-generative.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">PMF and their applications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/embeddings-angle.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Word Embeddings and Vector Angles</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Data Science Tools</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/intro-numpy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to NumPy</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/introduction-pandas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Pandas</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/introduction-matplotlib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to Matplotlib</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Interactive &amp; Quizzes</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/widgets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interactive Data Exploration with Jupyter Widgets</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/quiz1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Analysis Quiz - Pandas GroupBy Operations</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks/images-joint-distribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Images and Joint Distributions</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#probability-mass-functions-pmf-and-their-applications" id="toc-probability-mass-functions-pmf-and-their-applications" class="nav-link active" data-scroll-target="#probability-mass-functions-pmf-and-their-applications">Probability Mass Functions (PMF) and Their Applications</a>
  <ul class="collapse">
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a></li>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link" data-scroll-target="#learning-objectives">Learning Objectives</a></li>
  <li><a href="#theoretical-background" id="toc-theoretical-background" class="nav-link" data-scroll-target="#theoretical-background">Theoretical Background</a>
  <ul class="collapse">
  <li><a href="#definition-of-probability-mass-function" id="toc-definition-of-probability-mass-function" class="nav-link" data-scroll-target="#definition-of-probability-mass-function">Definition of Probability Mass Function</a></li>
  <li><a href="#key-properties-of-pmf" id="toc-key-properties-of-pmf" class="nav-link" data-scroll-target="#key-properties-of-pmf">Key Properties of PMF:</a></li>
  <li><a href="#common-discrete-distributions" id="toc-common-discrete-distributions" class="nav-link" data-scroll-target="#common-discrete-distributions">Common Discrete Distributions:</a></li>
  <li><a href="#connection-to-machine-learning" id="toc-connection-to-machine-learning" class="nav-link" data-scroll-target="#connection-to-machine-learning">Connection to Machine Learning</a></li>
  </ul></li>
  <li><a href="#practical-implementation" id="toc-practical-implementation" class="nav-link" data-scroll-target="#practical-implementation">Practical Implementation</a></li>
  <li><a href="#example-1-understanding-basic-pmfs" id="toc-example-1-understanding-basic-pmfs" class="nav-link" data-scroll-target="#example-1-understanding-basic-pmfs">Example 1: Understanding Basic PMFs</a></li>
  <li><a href="#example-2-bernoulli-distribution-and-binary-classification" id="toc-example-2-bernoulli-distribution-and-binary-classification" class="nav-link" data-scroll-target="#example-2-bernoulli-distribution-and-binary-classification">Example 2: Bernoulli Distribution and Binary Classification</a>
  <ul class="collapse">
  <li><a href="#generating-synthetic-binary-classification-data" id="toc-generating-synthetic-binary-classification-data" class="nav-link" data-scroll-target="#generating-synthetic-binary-classification-data">Generating Synthetic Binary Classification Data</a></li>
  <li><a href="#visualizing-the-bernoulli-pmf-in-action" id="toc-visualizing-the-bernoulli-pmf-in-action" class="nav-link" data-scroll-target="#visualizing-the-bernoulli-pmf-in-action">Visualizing the Bernoulli PMF in Action</a></li>
  <li><a href="#understanding-the-learning-process-maximum-likelihood-estimation" id="toc-understanding-the-learning-process-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#understanding-the-learning-process-maximum-likelihood-estimation">Understanding the Learning Process: Maximum Likelihood Estimation</a></li>
  </ul></li>
  <li><a href="#summary-and-key-takeaways" id="toc-summary-and-key-takeaways" class="nav-link" data-scroll-target="#summary-and-key-takeaways">Summary and Key Takeaways</a>
  <ul class="collapse">
  <li><a href="#what-weve-learned-about-pmfs" id="toc-what-weve-learned-about-pmfs" class="nav-link" data-scroll-target="#what-weve-learned-about-pmfs">What We’ve Learned About PMFs:</a></li>
  <li><a href="#mathematical-connections" id="toc-mathematical-connections" class="nav-link" data-scroll-target="#mathematical-connections">Mathematical Connections:</a></li>
  <li><a href="#key-insights-for-data-science" id="toc-key-insights-for-data-science" class="nav-link" data-scroll-target="#key-insights-for-data-science">Key Insights for Data Science:</a></li>
  <li><a href="#real-world-applications" id="toc-real-world-applications" class="nav-link" data-scroll-target="#real-world-applications">Real-World Applications:</a></li>
  <li><a href="#connection-to-broader-topics" id="toc-connection-to-broader-topics" class="nav-link" data-scroll-target="#connection-to-broader-topics">Connection to Broader Topics:</a></li>
  </ul></li>
  <li><a href="#example-3-multinomial-and-categorical-distributions" id="toc-example-3-multinomial-and-categorical-distributions" class="nav-link" data-scroll-target="#example-3-multinomial-and-categorical-distributions">Example 3: Multinomial and Categorical Distributions</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.dev/nipunbatra/psdv-teaching/blob/main/notebooks/logistic-regression-generative.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/nipunbatra/psdv-teaching/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks/pca.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../notebooks/logistic-regression-generative.html">PMF and their applications</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">PMF and their applications</h1>
  <div class="quarto-categories">
    <div class="quarto-category">ML</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Nipun Batra </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 11, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<div id="cell-1" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="im">import</span> torch </span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-5"><a href="#cb1-5"></a></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="co"># Retina mode</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="op">%</span>config InlineBackend.figure_format <span class="op">=</span> <span class="st">'retina'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="probability-mass-functions-pmf-and-their-applications" class="level1">
<h1>Probability Mass Functions (PMF) and Their Applications</h1>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Probability Mass Functions (PMF) are fundamental tools for describing the behavior of discrete random variables. A PMF tells us the probability that a discrete random variable takes each of its possible values. This concept is essential for understanding many real-world phenomena, from coin flips and dice rolls to classification problems in machine learning.</p>
<p>In this notebook, we’ll explore PMFs through both theoretical foundations and practical applications, including their connection to logistic regression - one of the most important classification algorithms in machine learning. We’ll see how the Bernoulli distribution (a special PMF) naturally leads to logistic regression for binary classification problems.</p>
</section>
<section id="learning-objectives" class="level2">
<h2 class="anchored" data-anchor-id="learning-objectives">Learning Objectives</h2>
<p>By the end of this notebook, you will be able to:</p>
<ol type="1">
<li><strong>Define</strong> and <strong>interpret</strong> Probability Mass Functions (PMF)</li>
<li><strong>Distinguish</strong> between PMF, PDF, and CDF</li>
<li><strong>Work with</strong> common discrete distributions (Bernoulli, Binomial, Categorical)</li>
<li><strong>Apply</strong> PMFs to real-world modeling scenarios</li>
<li><strong>Connect</strong> PMFs to logistic regression for classification</li>
<li><strong>Implement</strong> and <strong>visualize</strong> PMF-based models using Python</li>
<li><strong>Understand</strong> the generative vs.&nbsp;discriminative modeling paradigm</li>
</ol>
</section>
<section id="theoretical-background" class="level2">
<h2 class="anchored" data-anchor-id="theoretical-background">Theoretical Background</h2>
<section id="definition-of-probability-mass-function" class="level3">
<h3 class="anchored" data-anchor-id="definition-of-probability-mass-function">Definition of Probability Mass Function</h3>
<p>For a discrete random variable <span class="math inline">\(X\)</span> that can take values <span class="math inline">\(x_1, x_2, \ldots, x_k\)</span>, the <strong>Probability Mass Function</strong> (PMF) is:</p>
<p><span class="math display">\[P(X = x_i) = p_i\]</span></p>
<p>where <span class="math inline">\(p_i \geq 0\)</span> for all <span class="math inline">\(i\)</span>, and <span class="math inline">\(\sum_{i=1}^k p_i = 1\)</span>.</p>
</section>
<section id="key-properties-of-pmf" class="level3">
<h3 class="anchored" data-anchor-id="key-properties-of-pmf">Key Properties of PMF:</h3>
<ol type="1">
<li><strong>Non-negativity</strong>: <span class="math inline">\(P(X = x) \geq 0\)</span> for all <span class="math inline">\(x\)</span></li>
<li><strong>Normalization</strong>: <span class="math inline">\(\sum_{\text{all } x} P(X = x) = 1\)</span></li>
<li><strong>Additivity</strong>: <span class="math inline">\(P(X \in A) = \sum_{x \in A} P(X = x)\)</span> for any set <span class="math inline">\(A\)</span></li>
</ol>
</section>
<section id="common-discrete-distributions" class="level3">
<h3 class="anchored" data-anchor-id="common-discrete-distributions">Common Discrete Distributions:</h3>
<section id="bernoulli-distribution" class="level4">
<h4 class="anchored" data-anchor-id="bernoulli-distribution">1. Bernoulli Distribution</h4>
<p>For binary outcomes (success/failure): <span class="math display">\[P(X = 1) = p, \quad P(X = 0) = 1-p\]</span></p>
</section>
<section id="binomial-distribution" class="level4">
<h4 class="anchored" data-anchor-id="binomial-distribution">2. Binomial Distribution</h4>
<p>For <span class="math inline">\(n\)</span> independent Bernoulli trials: <span class="math display">\[P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}\]</span></p>
</section>
<section id="categorical-distribution" class="level4">
<h4 class="anchored" data-anchor-id="categorical-distribution">3. Categorical Distribution</h4>
<p>For <span class="math inline">\(k\)</span> mutually exclusive outcomes: <span class="math display">\[P(X = i) = p_i, \quad \sum_{i=1}^k p_i = 1\]</span></p>
</section>
</section>
<section id="connection-to-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="connection-to-machine-learning">Connection to Machine Learning</h3>
<p>PMFs are fundamental to many machine learning algorithms: - <strong>Classification</strong>: Predicting discrete class labels - <strong>Generative Models</strong>: Modeling the joint distribution <span class="math inline">\(P(X, Y)\)</span> - <strong>Discriminative Models</strong>: Modeling the conditional distribution <span class="math inline">\(P(Y|X)\)</span></p>
<hr>
</section>
</section>
<section id="practical-implementation" class="level2">
<h2 class="anchored" data-anchor-id="practical-implementation">Practical Implementation</h2>
</section>
<section id="example-1-understanding-basic-pmfs" class="level2">
<h2 class="anchored" data-anchor-id="example-1-understanding-basic-pmfs">Example 1: Understanding Basic PMFs</h2>
<p>Let’s start with simple examples to build intuition about PMFs.</p>
<div id="cell-4" class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="co"># Example 1: Basic PMF Examples</span></span>
<span id="cb2-2"><a href="#cb2-2"></a></span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="co"># 1. Fair Die PMF</span></span>
<span id="cb2-4"><a href="#cb2-4"></a>die_outcomes <span class="op">=</span> np.arange(<span class="dv">1</span>, <span class="dv">7</span>)  <span class="co"># {1, 2, 3, 4, 5, 6}</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>die_pmf <span class="op">=</span> np.ones(<span class="dv">6</span>) <span class="op">/</span> <span class="dv">6</span>  <span class="co"># Each outcome has probability 1/6</span></span>
<span id="cb2-6"><a href="#cb2-6"></a></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="co"># 2. Loaded Die PMF  </span></span>
<span id="cb2-8"><a href="#cb2-8"></a>loaded_die_pmf <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.4</span>])  <span class="co"># Favors 5 and 6</span></span>
<span id="cb2-9"><a href="#cb2-9"></a></span>
<span id="cb2-10"><a href="#cb2-10"></a><span class="co"># 3. Bernoulli PMF (Coin flip)</span></span>
<span id="cb2-11"><a href="#cb2-11"></a>coin_outcomes <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">1</span>])  <span class="co"># {Tails, Heads}</span></span>
<span id="cb2-12"><a href="#cb2-12"></a>coin_pmf <span class="op">=</span> np.array([<span class="fl">0.3</span>, <span class="fl">0.7</span>])  <span class="co"># Biased toward heads</span></span>
<span id="cb2-13"><a href="#cb2-13"></a></span>
<span id="cb2-14"><a href="#cb2-14"></a><span class="co"># Visualization</span></span>
<span id="cb2-15"><a href="#cb2-15"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb2-16"><a href="#cb2-16"></a></span>
<span id="cb2-17"><a href="#cb2-17"></a><span class="co"># Fair die</span></span>
<span id="cb2-18"><a href="#cb2-18"></a>axes[<span class="dv">0</span>].bar(die_outcomes, die_pmf, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb2-19"><a href="#cb2-19"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Fair Die PMF'</span>)</span>
<span id="cb2-20"><a href="#cb2-20"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Outcome'</span>)</span>
<span id="cb2-21"><a href="#cb2-21"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Probability'</span>)</span>
<span id="cb2-22"><a href="#cb2-22"></a>axes[<span class="dv">0</span>].set_ylim(<span class="dv">0</span>, <span class="fl">0.5</span>)</span>
<span id="cb2-23"><a href="#cb2-23"></a>axes[<span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb2-24"><a href="#cb2-24"></a></span>
<span id="cb2-25"><a href="#cb2-25"></a><span class="co"># Add probability values on bars</span></span>
<span id="cb2-26"><a href="#cb2-26"></a><span class="cf">for</span> i, p <span class="kw">in</span> <span class="bu">enumerate</span>(die_pmf):</span>
<span id="cb2-27"><a href="#cb2-27"></a>    axes[<span class="dv">0</span>].text(i<span class="op">+</span><span class="dv">1</span>, p<span class="op">+</span><span class="fl">0.01</span>, <span class="ss">f'</span><span class="sc">{</span>p<span class="sc">:.3f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb2-28"><a href="#cb2-28"></a></span>
<span id="cb2-29"><a href="#cb2-29"></a><span class="co"># Loaded die</span></span>
<span id="cb2-30"><a href="#cb2-30"></a>axes[<span class="dv">1</span>].bar(die_outcomes, loaded_die_pmf, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb2-31"><a href="#cb2-31"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Loaded Die PMF'</span>)</span>
<span id="cb2-32"><a href="#cb2-32"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Outcome'</span>)</span>
<span id="cb2-33"><a href="#cb2-33"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Probability'</span>)</span>
<span id="cb2-34"><a href="#cb2-34"></a>axes[<span class="dv">1</span>].set_ylim(<span class="dv">0</span>, <span class="fl">0.5</span>)</span>
<span id="cb2-35"><a href="#cb2-35"></a>axes[<span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb2-36"><a href="#cb2-36"></a></span>
<span id="cb2-37"><a href="#cb2-37"></a><span class="cf">for</span> i, p <span class="kw">in</span> <span class="bu">enumerate</span>(loaded_die_pmf):</span>
<span id="cb2-38"><a href="#cb2-38"></a>    axes[<span class="dv">1</span>].text(i<span class="op">+</span><span class="dv">1</span>, p<span class="op">+</span><span class="fl">0.01</span>, <span class="ss">f'</span><span class="sc">{</span>p<span class="sc">:.3f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb2-39"><a href="#cb2-39"></a></span>
<span id="cb2-40"><a href="#cb2-40"></a><span class="co"># Biased coin</span></span>
<span id="cb2-41"><a href="#cb2-41"></a>axes[<span class="dv">2</span>].bar(coin_outcomes, coin_pmf, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb2-42"><a href="#cb2-42"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'Biased Coin PMF'</span>)</span>
<span id="cb2-43"><a href="#cb2-43"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'Outcome (0=Tails, 1=Heads)'</span>)</span>
<span id="cb2-44"><a href="#cb2-44"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">'Probability'</span>)</span>
<span id="cb2-45"><a href="#cb2-45"></a>axes[<span class="dv">2</span>].set_ylim(<span class="dv">0</span>, <span class="fl">0.8</span>)</span>
<span id="cb2-46"><a href="#cb2-46"></a>axes[<span class="dv">2</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb2-47"><a href="#cb2-47"></a></span>
<span id="cb2-48"><a href="#cb2-48"></a><span class="cf">for</span> i, p <span class="kw">in</span> <span class="bu">enumerate</span>(coin_pmf):</span>
<span id="cb2-49"><a href="#cb2-49"></a>    axes[<span class="dv">2</span>].text(i, p<span class="op">+</span><span class="fl">0.02</span>, <span class="ss">f'</span><span class="sc">{</span>p<span class="sc">:.3f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb2-50"><a href="#cb2-50"></a></span>
<span id="cb2-51"><a href="#cb2-51"></a>plt.tight_layout()</span>
<span id="cb2-52"><a href="#cb2-52"></a>plt.show()</span>
<span id="cb2-53"><a href="#cb2-53"></a></span>
<span id="cb2-54"><a href="#cb2-54"></a><span class="co"># Verify PMF properties</span></span>
<span id="cb2-55"><a href="#cb2-55"></a><span class="bu">print</span>(<span class="st">"VERIFICATION OF PMF PROPERTIES:"</span>)</span>
<span id="cb2-56"><a href="#cb2-56"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">40</span>)</span>
<span id="cb2-57"><a href="#cb2-57"></a><span class="bu">print</span>(<span class="ss">f"Fair die:"</span>)</span>
<span id="cb2-58"><a href="#cb2-58"></a><span class="bu">print</span>(<span class="ss">f"  - All probabilities ≥ 0: </span><span class="sc">{</span><span class="bu">all</span>(die_pmf <span class="op">&gt;=</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-59"><a href="#cb2-59"></a><span class="bu">print</span>(<span class="ss">f"  - Sum = 1: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(die_pmf)<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb2-60"><a href="#cb2-60"></a></span>
<span id="cb2-61"><a href="#cb2-61"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Loaded die:"</span>)</span>
<span id="cb2-62"><a href="#cb2-62"></a><span class="bu">print</span>(<span class="ss">f"  - All probabilities ≥ 0: </span><span class="sc">{</span><span class="bu">all</span>(loaded_die_pmf <span class="op">&gt;=</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-63"><a href="#cb2-63"></a><span class="bu">print</span>(<span class="ss">f"  - Sum = 1: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(loaded_die_pmf)<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb2-64"><a href="#cb2-64"></a></span>
<span id="cb2-65"><a href="#cb2-65"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Biased coin:"</span>)</span>
<span id="cb2-66"><a href="#cb2-66"></a><span class="bu">print</span>(<span class="ss">f"  - All probabilities ≥ 0: </span><span class="sc">{</span><span class="bu">all</span>(coin_pmf <span class="op">&gt;=</span> <span class="dv">0</span>)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-67"><a href="#cb2-67"></a><span class="bu">print</span>(<span class="ss">f"  - Sum = 1: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(coin_pmf)<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb2-68"><a href="#cb2-68"></a></span>
<span id="cb2-69"><a href="#cb2-69"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Expected Values:"</span>)</span>
<span id="cb2-70"><a href="#cb2-70"></a><span class="bu">print</span>(<span class="ss">f"  - Fair die: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(die_outcomes <span class="op">*</span> die_pmf)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb2-71"><a href="#cb2-71"></a><span class="bu">print</span>(<span class="ss">f"  - Loaded die: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(die_outcomes <span class="op">*</span> loaded_die_pmf)<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb2-72"><a href="#cb2-72"></a><span class="bu">print</span>(<span class="ss">f"  - Biased coin: </span><span class="sc">{</span>np<span class="sc">.</span><span class="bu">sum</span>(coin_outcomes <span class="op">*</span> coin_pmf)<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="example-2-bernoulli-distribution-and-binary-classification" class="level2">
<h2 class="anchored" data-anchor-id="example-2-bernoulli-distribution-and-binary-classification">Example 2: Bernoulli Distribution and Binary Classification</h2>
<p>The Bernoulli distribution is fundamental to binary classification. Let’s explore how it connects to logistic regression.</p>
<section id="generating-synthetic-binary-classification-data" class="level3">
<h3 class="anchored" data-anchor-id="generating-synthetic-binary-classification-data">Generating Synthetic Binary Classification Data</h3>
<p>We’ll create a dataset where the class labels follow a Bernoulli distribution whose parameter depends on the input features.</p>
<p><strong>Understanding the Data Generation Process:</strong></p>
<ol type="1">
<li><strong>Linear Combination</strong>: <span class="math inline">\(z = w_1 x_1 + w_2 x_2 + b\)</span> (logits)</li>
<li><strong>Sigmoid Transformation</strong>: <span class="math inline">\(p = \sigma(z) = \frac{1}{1 + e^{-z}}\)</span></li>
<li><strong>Bernoulli Sampling</strong>: <span class="math inline">\(Y \sim \text{Bernoulli}(p)\)</span></li>
</ol>
<p>This creates a natural connection between continuous features and binary outcomes through the Bernoulli PMF.</p>
<div id="cell-8" class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a><span class="co"># Visualize how the Bernoulli PMF varies across feature space</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">12</span>))</span>
<span id="cb3-3"><a href="#cb3-3"></a></span>
<span id="cb3-4"><a href="#cb3-4"></a><span class="co"># 1. Probability surface</span></span>
<span id="cb3-5"><a href="#cb3-5"></a>x1_range <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">50</span>)</span>
<span id="cb3-6"><a href="#cb3-6"></a>x2_range <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">50</span>)</span>
<span id="cb3-7"><a href="#cb3-7"></a>X1_grid, X2_grid <span class="op">=</span> np.meshgrid(x1_range, x2_range)</span>
<span id="cb3-8"><a href="#cb3-8"></a></span>
<span id="cb3-9"><a href="#cb3-9"></a><span class="co"># Compute probability for each point</span></span>
<span id="cb3-10"><a href="#cb3-10"></a>logits_grid <span class="op">=</span> w1 <span class="op">*</span> X1_grid <span class="op">+</span> w2 <span class="op">*</span> X2_grid <span class="op">+</span> b</span>
<span id="cb3-11"><a href="#cb3-11"></a>prob_grid <span class="op">=</span> torch.sigmoid(torch.tensor(logits_grid)).numpy()</span>
<span id="cb3-12"><a href="#cb3-12"></a></span>
<span id="cb3-13"><a href="#cb3-13"></a>contour <span class="op">=</span> axes[<span class="dv">0</span>, <span class="dv">0</span>].contourf(X1_grid, X2_grid, prob_grid, levels<span class="op">=</span><span class="dv">20</span>, cmap<span class="op">=</span><span class="st">'RdYlBu_r'</span>)</span>
<span id="cb3-14"><a href="#cb3-14"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Bernoulli Parameter p(x₁, x₂)</span><span class="ch">\n</span><span class="st">Probability of Class 1'</span>)</span>
<span id="cb3-15"><a href="#cb3-15"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'Feature 1 (X₁)'</span>)</span>
<span id="cb3-16"><a href="#cb3-16"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'Feature 2 (X₂)'</span>)</span>
<span id="cb3-17"><a href="#cb3-17"></a>plt.colorbar(contour, ax<span class="op">=</span>axes[<span class="dv">0</span>, <span class="dv">0</span>])</span>
<span id="cb3-18"><a href="#cb3-18"></a></span>
<span id="cb3-19"><a href="#cb3-19"></a><span class="co"># Add decision boundary (p = 0.5)</span></span>
<span id="cb3-20"><a href="#cb3-20"></a>contour_line <span class="op">=</span> axes[<span class="dv">0</span>, <span class="dv">0</span>].contour(X1_grid, X2_grid, prob_grid, levels<span class="op">=</span>[<span class="fl">0.5</span>], colors<span class="op">=</span><span class="st">'black'</span>, linewidths<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-21"><a href="#cb3-21"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].clabel(contour_line, inline<span class="op">=</span><span class="va">True</span>, fontsize<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb3-22"><a href="#cb3-22"></a></span>
<span id="cb3-23"><a href="#cb3-23"></a><span class="co"># 2. Data points with probability coloring</span></span>
<span id="cb3-24"><a href="#cb3-24"></a>X1_np, X2_np, Y_np <span class="op">=</span> X1.numpy(), X2.numpy(), Y.numpy()</span>
<span id="cb3-25"><a href="#cb3-25"></a>scatter <span class="op">=</span> axes[<span class="dv">0</span>, <span class="dv">1</span>].scatter(X1_np, X2_np, c<span class="op">=</span>prob_Y.numpy(), cmap<span class="op">=</span><span class="st">'RdYlBu_r'</span>, </span>
<span id="cb3-26"><a href="#cb3-26"></a>                            alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">30</span>, edgecolors<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb3-27"><a href="#cb3-27"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_title(<span class="st">'Data Points Colored by</span><span class="ch">\n</span><span class="st">Bernoulli Parameter p'</span>)</span>
<span id="cb3-28"><a href="#cb3-28"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_xlabel(<span class="st">'Feature 1 (X₁)'</span>)</span>
<span id="cb3-29"><a href="#cb3-29"></a>axes[<span class="dv">0</span>, <span class="dv">1</span>].set_ylabel(<span class="st">'Feature 2 (X₂)'</span>)</span>
<span id="cb3-30"><a href="#cb3-30"></a>plt.colorbar(scatter, ax<span class="op">=</span>axes[<span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb3-31"><a href="#cb3-31"></a></span>
<span id="cb3-32"><a href="#cb3-32"></a><span class="co"># 3. Actual class labels</span></span>
<span id="cb3-33"><a href="#cb3-33"></a>axes[<span class="dv">0</span>, <span class="dv">2</span>].scatter(X1_np[Y_np <span class="op">==</span> <span class="dv">0</span>], X2_np[Y_np <span class="op">==</span> <span class="dv">0</span>], color<span class="op">=</span><span class="st">"blue"</span>, label<span class="op">=</span><span class="st">"Class 0"</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb3-34"><a href="#cb3-34"></a>axes[<span class="dv">0</span>, <span class="dv">2</span>].scatter(X1_np[Y_np <span class="op">==</span> <span class="dv">1</span>], X2_np[Y_np <span class="op">==</span> <span class="dv">1</span>], color<span class="op">=</span><span class="st">"red"</span>, label<span class="op">=</span><span class="st">"Class 1"</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb3-35"><a href="#cb3-35"></a>axes[<span class="dv">0</span>, <span class="dv">2</span>].set_title(<span class="st">'Actual Class Labels</span><span class="ch">\n</span><span class="st">(Bernoulli Realizations)'</span>)</span>
<span id="cb3-36"><a href="#cb3-36"></a>axes[<span class="dv">0</span>, <span class="dv">2</span>].set_xlabel(<span class="st">'Feature 1 (X₁)'</span>)</span>
<span id="cb3-37"><a href="#cb3-37"></a>axes[<span class="dv">0</span>, <span class="dv">2</span>].set_ylabel(<span class="st">'Feature 2 (X₂)'</span>)</span>
<span id="cb3-38"><a href="#cb3-38"></a>axes[<span class="dv">0</span>, <span class="dv">2</span>].legend()</span>
<span id="cb3-39"><a href="#cb3-39"></a></span>
<span id="cb3-40"><a href="#cb3-40"></a><span class="co"># 4. PMF visualization for specific points</span></span>
<span id="cb3-41"><a href="#cb3-41"></a>sample_points <span class="op">=</span> [(<span class="dv">1</span>, <span class="dv">1</span>), (<span class="fl">2.5</span>, <span class="fl">2.5</span>), (<span class="dv">4</span>, <span class="dv">1</span>)]</span>
<span id="cb3-42"><a href="#cb3-42"></a>colors <span class="op">=</span> [<span class="st">'blue'</span>, <span class="st">'purple'</span>, <span class="st">'red'</span>]</span>
<span id="cb3-43"><a href="#cb3-43"></a></span>
<span id="cb3-44"><a href="#cb3-44"></a><span class="cf">for</span> i, (x1_val, x2_val) <span class="kw">in</span> <span class="bu">enumerate</span>(sample_points):</span>
<span id="cb3-45"><a href="#cb3-45"></a>    <span class="co"># Calculate probability for this point</span></span>
<span id="cb3-46"><a href="#cb3-46"></a>    logit_val <span class="op">=</span> w1 <span class="op">*</span> x1_val <span class="op">+</span> w2 <span class="op">*</span> x2_val <span class="op">+</span> b</span>
<span id="cb3-47"><a href="#cb3-47"></a>    p_val <span class="op">=</span> torch.sigmoid(torch.tensor(logit_val)).item()</span>
<span id="cb3-48"><a href="#cb3-48"></a>    </span>
<span id="cb3-49"><a href="#cb3-49"></a>    <span class="co"># Plot the Bernoulli PMF for this point</span></span>
<span id="cb3-50"><a href="#cb3-50"></a>    outcomes <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb3-51"><a href="#cb3-51"></a>    probabilities <span class="op">=</span> [<span class="dv">1</span> <span class="op">-</span> p_val, p_val]</span>
<span id="cb3-52"><a href="#cb3-52"></a>    </span>
<span id="cb3-53"><a href="#cb3-53"></a>    ax <span class="op">=</span> axes[<span class="dv">1</span>, i]</span>
<span id="cb3-54"><a href="#cb3-54"></a>    bars <span class="op">=</span> ax.bar(outcomes, probabilities, alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span>colors[i])</span>
<span id="cb3-55"><a href="#cb3-55"></a>    ax.set_title(<span class="ss">f'Bernoulli PMF at (</span><span class="sc">{</span>x1_val<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>x2_val<span class="sc">}</span><span class="ss">)</span><span class="ch">\n</span><span class="ss">p = </span><span class="sc">{</span>p_val<span class="sc">:.3f}</span><span class="ss">'</span>)</span>
<span id="cb3-56"><a href="#cb3-56"></a>    ax.set_xlabel(<span class="st">'Class'</span>)</span>
<span id="cb3-57"><a href="#cb3-57"></a>    ax.set_ylabel(<span class="st">'Probability'</span>)</span>
<span id="cb3-58"><a href="#cb3-58"></a>    ax.set_ylim(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb3-59"><a href="#cb3-59"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb3-60"><a href="#cb3-60"></a>    </span>
<span id="cb3-61"><a href="#cb3-61"></a>    <span class="co"># Add probability values on bars</span></span>
<span id="cb3-62"><a href="#cb3-62"></a>    <span class="cf">for</span> j, prob <span class="kw">in</span> <span class="bu">enumerate</span>(probabilities):</span>
<span id="cb3-63"><a href="#cb3-63"></a>        ax.text(j, prob <span class="op">+</span> <span class="fl">0.02</span>, <span class="ss">f'</span><span class="sc">{</span>prob<span class="sc">:.3f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb3-64"><a href="#cb3-64"></a>    </span>
<span id="cb3-65"><a href="#cb3-65"></a>    <span class="co"># Mark this point on the main plot</span></span>
<span id="cb3-66"><a href="#cb3-66"></a>    axes[<span class="dv">0</span>, <span class="dv">1</span>].plot(x1_val, x2_val, <span class="st">'o'</span>, color<span class="op">=</span>colors[i], markersize<span class="op">=</span><span class="dv">10</span>, </span>
<span id="cb3-67"><a href="#cb3-67"></a>                   markeredgecolor<span class="op">=</span><span class="st">'black'</span>, markeredgewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-68"><a href="#cb3-68"></a>    axes[<span class="dv">0</span>, <span class="dv">1</span>].text(x1_val <span class="op">+</span> <span class="fl">0.1</span>, x2_val <span class="op">+</span> <span class="fl">0.1</span>, <span class="ss">f'Point </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>, </span>
<span id="cb3-69"><a href="#cb3-69"></a>                   color<span class="op">=</span>colors[i], fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb3-70"><a href="#cb3-70"></a></span>
<span id="cb3-71"><a href="#cb3-71"></a>plt.tight_layout()</span>
<span id="cb3-72"><a href="#cb3-72"></a>plt.show()</span>
<span id="cb3-73"><a href="#cb3-73"></a></span>
<span id="cb3-74"><a href="#cb3-74"></a><span class="bu">print</span>(<span class="st">"PMF ANALYSIS FOR DIFFERENT POINTS:"</span>)</span>
<span id="cb3-75"><a href="#cb3-75"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb3-76"><a href="#cb3-76"></a><span class="cf">for</span> i, (x1_val, x2_val) <span class="kw">in</span> <span class="bu">enumerate</span>(sample_points):</span>
<span id="cb3-77"><a href="#cb3-77"></a>    logit_val <span class="op">=</span> w1 <span class="op">*</span> x1_val <span class="op">+</span> w2 <span class="op">*</span> x2_val <span class="op">+</span> b</span>
<span id="cb3-78"><a href="#cb3-78"></a>    p_val <span class="op">=</span> torch.sigmoid(torch.tensor(logit_val)).item()</span>
<span id="cb3-79"><a href="#cb3-79"></a>    </span>
<span id="cb3-80"><a href="#cb3-80"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Point </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: (</span><span class="sc">{</span>x1_val<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>x2_val<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb3-81"><a href="#cb3-81"></a>    <span class="bu">print</span>(<span class="ss">f"  Logit z = </span><span class="sc">{</span>w1<span class="sc">:.1f}</span><span class="ss">×</span><span class="sc">{</span>x1_val<span class="sc">}</span><span class="ss"> + </span><span class="sc">{</span>w2<span class="sc">:.1f}</span><span class="ss">×</span><span class="sc">{</span>x2_val<span class="sc">}</span><span class="ss"> + </span><span class="sc">{</span>b<span class="sc">:.1f}</span><span class="ss"> = </span><span class="sc">{</span>logit_val<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb3-82"><a href="#cb3-82"></a>    <span class="bu">print</span>(<span class="ss">f"  Probability p = σ(</span><span class="sc">{</span>logit_val<span class="sc">:.3f}</span><span class="ss">) = </span><span class="sc">{</span>p_val<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb3-83"><a href="#cb3-83"></a>    <span class="bu">print</span>(<span class="ss">f"  Bernoulli PMF: P(Y=0) = </span><span class="sc">{</span><span class="dv">1</span><span class="op">-</span>p_val<span class="sc">:.3f}</span><span class="ss">, P(Y=1) = </span><span class="sc">{</span>p_val<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb3-84"><a href="#cb3-84"></a>    <span class="bu">print</span>(<span class="ss">f"  Most likely class: </span><span class="sc">{</span><span class="dv">1</span> <span class="cf">if</span> p_val <span class="op">&gt;</span> <span class="fl">0.5</span> <span class="cf">else</span> <span class="dv">0</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-85"><a href="#cb3-85"></a></span>
<span id="cb3-86"><a href="#cb3-86"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Decision boundary equation: </span><span class="sc">{</span>w1<span class="sc">:.1f}</span><span class="ss">×X₁ + </span><span class="sc">{</span>w2<span class="sc">:.1f}</span><span class="ss">×X₂ + </span><span class="sc">{</span>b<span class="sc">:.1f}</span><span class="ss"> = 0"</span>)</span>
<span id="cb3-87"><a href="#cb3-87"></a><span class="bu">print</span>(<span class="ss">f"Simplified: X₂ = </span><span class="sc">{</span><span class="op">-</span>w1<span class="op">/</span>w2<span class="sc">:.3f}</span><span class="ss">×X₁ + </span><span class="sc">{</span><span class="op">-</span>b<span class="op">/</span>w2<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="visualizing-the-bernoulli-pmf-in-action" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-the-bernoulli-pmf-in-action">Visualizing the Bernoulli PMF in Action</h3>
<p>Let’s examine how the Bernoulli PMF varies across our feature space:</p>
<div id="cell-10" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># Set random seed</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>torch.manual_seed(<span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>&lt;torch._C.Generator at 0x11e27cab0&gt;</code></pre>
</div>
</div>
</section>
<section id="understanding-the-learning-process-maximum-likelihood-estimation" class="level3">
<h3 class="anchored" data-anchor-id="understanding-the-learning-process-maximum-likelihood-estimation">Understanding the Learning Process: Maximum Likelihood Estimation</h3>
<p>Logistic regression learns by finding parameters that maximize the likelihood of observing our data. This is directly connected to the Bernoulli PMF!</p>
<hr>
</section>
</section>
<section id="summary-and-key-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="summary-and-key-takeaways">Summary and Key Takeaways</h2>
<section id="what-weve-learned-about-pmfs" class="level3">
<h3 class="anchored" data-anchor-id="what-weve-learned-about-pmfs">What We’ve Learned About PMFs:</h3>
<ol type="1">
<li><p><strong>Definition and Properties</strong>: PMFs describe discrete random variables with non-negative probabilities that sum to 1</p></li>
<li><p><strong>Connection to Machine Learning</strong>:</p>
<ul>
<li><strong>Bernoulli Distribution</strong> → <strong>Binary Classification</strong> → <strong>Logistic Regression</strong></li>
<li><strong>Categorical Distribution</strong> → <strong>Multi-class Classification</strong> → <strong>Softmax Regression</strong></li>
</ul></li>
<li><p><strong>Maximum Likelihood Estimation</strong>: Learning algorithms find parameters that maximize the likelihood of observed data under the assumed PMF</p></li>
<li><p><strong>Practical Applications</strong>: PMFs model discrete outcomes in classification, counting processes, and decision-making scenarios</p></li>
</ol>
</section>
<section id="mathematical-connections" class="level3">
<h3 class="anchored" data-anchor-id="mathematical-connections">Mathematical Connections:</h3>
<p><strong>Binary Classification (Bernoulli PMF):</strong> - <span class="math inline">\(P(Y = 1|X) = \sigma(w^T X + b)\)</span> where <span class="math inline">\(\sigma(z) = \frac{1}{1+e^{-z}}\)</span> - Loss function: <span class="math inline">\(-\sum_i [y_i \log p_i + (1-y_i) \log(1-p_i)]\)</span></p>
<p><strong>Multi-class Classification (Categorical PMF):</strong> - <span class="math inline">\(P(Y = k|X) = \frac{e^{w_k^T X + b_k}}{\sum_{j=1}^K e^{w_j^T X + b_j}}\)</span> (softmax) - Loss function: <span class="math inline">\(-\sum_i \sum_k y_{ik} \log p_{ik}\)</span> (cross-entropy)</p>
</section>
<section id="key-insights-for-data-science" class="level3">
<h3 class="anchored" data-anchor-id="key-insights-for-data-science">Key Insights for Data Science:</h3>
<ol type="1">
<li><strong>Probabilistic Foundation</strong>: Classification is fundamentally about modeling conditional PMFs</li>
<li><strong>Generative vs.&nbsp;Discriminative</strong>: PMFs can model <span class="math inline">\(P(X,Y)\)</span> (generative) or <span class="math inline">\(P(Y|X)\)</span> (discriminative)</li>
<li><strong>Uncertainty Quantification</strong>: PMFs naturally provide prediction confidence through probabilities</li>
<li><strong>Model Selection</strong>: Different PMF assumptions lead to different algorithms (Naive Bayes vs.&nbsp;Logistic Regression)</li>
</ol>
</section>
<section id="real-world-applications" class="level3">
<h3 class="anchored" data-anchor-id="real-world-applications">Real-World Applications:</h3>
<ul>
<li><strong>Medical Diagnosis</strong>: Modeling disease presence/absence (Bernoulli)</li>
<li><strong>Customer Behavior</strong>: Predicting purchase categories (Categorical)<br>
</li>
<li><strong>Quality Control</strong>: Counting defects (Poisson/Binomial)</li>
<li><strong>Natural Language</strong>: Word occurrence in documents (Multinomial)</li>
<li><strong>Recommendation Systems</strong>: Item preferences (Categorical/Multinomial)</li>
</ul>
</section>
<section id="connection-to-broader-topics" class="level3">
<h3 class="anchored" data-anchor-id="connection-to-broader-topics">Connection to Broader Topics:</h3>
<ul>
<li><strong>Exponential Family</strong>: Bernoulli and Categorical are exponential family distributions</li>
<li><strong>Information Theory</strong>: Cross-entropy loss connects to information theory</li>
<li><strong>Bayesian Statistics</strong>: PMFs serve as likelihood functions in Bayesian inference</li>
<li><strong>Causal Inference</strong>: Understanding <span class="math inline">\(P(Y|do(X))\)</span> vs.&nbsp;<span class="math inline">\(P(Y|X)\)</span></li>
</ul>
<p>Understanding PMFs provides the probabilistic foundation for classification algorithms, uncertainty quantification, and decision-making under uncertainty. This knowledge bridges pure probability theory with practical machine learning applications.</p>
<div id="cell-13" class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="co"># Example: Categorical Distribution (Multinomial Classification)</span></span>
<span id="cb6-2"><a href="#cb6-2"></a></span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="co"># Simulate a 3-class classification problem</span></span>
<span id="cb6-4"><a href="#cb6-4"></a>torch.manual_seed(<span class="dv">123</span>)</span>
<span id="cb6-5"><a href="#cb6-5"></a>n_samples <span class="op">=</span> <span class="dv">500</span></span>
<span id="cb6-6"><a href="#cb6-6"></a>n_classes <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb6-7"><a href="#cb6-7"></a></span>
<span id="cb6-8"><a href="#cb6-8"></a><span class="co"># Generate 2D features</span></span>
<span id="cb6-9"><a href="#cb6-9"></a>X_multi <span class="op">=</span> torch.distributions.Uniform(<span class="dv">0</span>, <span class="dv">6</span>).sample((n_samples, <span class="dv">2</span>))</span>
<span id="cb6-10"><a href="#cb6-10"></a></span>
<span id="cb6-11"><a href="#cb6-11"></a><span class="co"># Define parameters for 3-class softmax</span></span>
<span id="cb6-12"><a href="#cb6-12"></a><span class="co"># Each class has its own linear function</span></span>
<span id="cb6-13"><a href="#cb6-13"></a>W <span class="op">=</span> torch.tensor([[<span class="fl">1.0</span>, <span class="op">-</span><span class="fl">0.5</span>],   <span class="co"># Class 0 weights</span></span>
<span id="cb6-14"><a href="#cb6-14"></a>                  [<span class="op">-</span><span class="fl">0.8</span>, <span class="fl">1.2</span>],   <span class="co"># Class 1 weights  </span></span>
<span id="cb6-15"><a href="#cb6-15"></a>                  [<span class="fl">0.3</span>, <span class="op">-</span><span class="fl">0.7</span>]])  <span class="co"># Class 2 weights</span></span>
<span id="cb6-16"><a href="#cb6-16"></a>b <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">0.5</span>, <span class="fl">1.0</span>])  <span class="co"># Class biases</span></span>
<span id="cb6-17"><a href="#cb6-17"></a></span>
<span id="cb6-18"><a href="#cb6-18"></a><span class="co"># Compute logits for each class</span></span>
<span id="cb6-19"><a href="#cb6-19"></a>logits_multi <span class="op">=</span> torch.matmul(X_multi, W.T) <span class="op">+</span> b  <span class="co"># (n_samples, n_classes)</span></span>
<span id="cb6-20"><a href="#cb6-20"></a></span>
<span id="cb6-21"><a href="#cb6-21"></a><span class="co"># Apply softmax to get class probabilities (categorical PMF parameters)</span></span>
<span id="cb6-22"><a href="#cb6-22"></a>probs_multi <span class="op">=</span> torch.softmax(logits_multi, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-23"><a href="#cb6-23"></a></span>
<span id="cb6-24"><a href="#cb6-24"></a><span class="co"># Sample class labels from categorical distribution</span></span>
<span id="cb6-25"><a href="#cb6-25"></a>Y_multi <span class="op">=</span> torch.distributions.Categorical(probs_multi).sample()</span>
<span id="cb6-26"><a href="#cb6-26"></a></span>
<span id="cb6-27"><a href="#cb6-27"></a><span class="co"># Visualization</span></span>
<span id="cb6-28"><a href="#cb6-28"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">12</span>))</span>
<span id="cb6-29"><a href="#cb6-29"></a></span>
<span id="cb6-30"><a href="#cb6-30"></a><span class="co"># 1. Data points colored by true class</span></span>
<span id="cb6-31"><a href="#cb6-31"></a>colors <span class="op">=</span> [<span class="st">'blue'</span>, <span class="st">'red'</span>, <span class="st">'green'</span>]</span>
<span id="cb6-32"><a href="#cb6-32"></a>class_names <span class="op">=</span> [<span class="st">'Class 0'</span>, <span class="st">'Class 1'</span>, <span class="st">'Class 2'</span>]</span>
<span id="cb6-33"><a href="#cb6-33"></a></span>
<span id="cb6-34"><a href="#cb6-34"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_classes):</span>
<span id="cb6-35"><a href="#cb6-35"></a>    mask <span class="op">=</span> (Y_multi <span class="op">==</span> i)</span>
<span id="cb6-36"><a href="#cb6-36"></a>    axes[<span class="dv">0</span>, <span class="dv">0</span>].scatter(X_multi[mask, <span class="dv">0</span>], X_multi[mask, <span class="dv">1</span>], </span>
<span id="cb6-37"><a href="#cb6-37"></a>                      color<span class="op">=</span>colors[i], label<span class="op">=</span>class_names[i], alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb6-38"><a href="#cb6-38"></a></span>
<span id="cb6-39"><a href="#cb6-39"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'3-Class Classification Data</span><span class="ch">\n</span><span class="st">(Categorical Distribution Samples)'</span>)</span>
<span id="cb6-40"><a href="#cb6-40"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_xlabel(<span class="st">'Feature 1'</span>)</span>
<span id="cb6-41"><a href="#cb6-41"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_ylabel(<span class="st">'Feature 2'</span>)</span>
<span id="cb6-42"><a href="#cb6-42"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].legend()</span>
<span id="cb6-43"><a href="#cb6-43"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb6-44"><a href="#cb6-44"></a></span>
<span id="cb6-45"><a href="#cb6-45"></a><span class="co"># 2-4. Probability maps for each class</span></span>
<span id="cb6-46"><a href="#cb6-46"></a>x1_range <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">6</span>, <span class="dv">50</span>)</span>
<span id="cb6-47"><a href="#cb6-47"></a>x2_range <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">6</span>, <span class="dv">50</span>)</span>
<span id="cb6-48"><a href="#cb6-48"></a>X1_grid, X2_grid <span class="op">=</span> np.meshgrid(x1_range, x2_range)</span>
<span id="cb6-49"><a href="#cb6-49"></a>grid_points <span class="op">=</span> torch.tensor(np.c_[X1_grid.ravel(), X2_grid.ravel()], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb6-50"><a href="#cb6-50"></a></span>
<span id="cb6-51"><a href="#cb6-51"></a><span class="co"># Compute probabilities for grid</span></span>
<span id="cb6-52"><a href="#cb6-52"></a>logits_grid <span class="op">=</span> torch.matmul(grid_points, W.T) <span class="op">+</span> b</span>
<span id="cb6-53"><a href="#cb6-53"></a>probs_grid <span class="op">=</span> torch.softmax(logits_grid, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb6-54"><a href="#cb6-54"></a></span>
<span id="cb6-55"><a href="#cb6-55"></a><span class="cf">for</span> class_idx <span class="kw">in</span> <span class="bu">range</span>(n_classes):</span>
<span id="cb6-56"><a href="#cb6-56"></a>    ax <span class="op">=</span> axes[<span class="dv">0</span>, class_idx <span class="op">+</span> <span class="dv">1</span>]</span>
<span id="cb6-57"><a href="#cb6-57"></a>    prob_map <span class="op">=</span> probs_grid[:, class_idx].reshape(X1_grid.shape)</span>
<span id="cb6-58"><a href="#cb6-58"></a>    </span>
<span id="cb6-59"><a href="#cb6-59"></a>    contour <span class="op">=</span> ax.contourf(X1_grid, X2_grid, prob_map, levels<span class="op">=</span><span class="dv">20</span>, cmap<span class="op">=</span><span class="st">'Reds'</span>)</span>
<span id="cb6-60"><a href="#cb6-60"></a>    ax.set_title(<span class="ss">f'P(Y = </span><span class="sc">{</span>class_idx<span class="sc">}</span><span class="ss"> | X)</span><span class="ch">\n</span><span class="ss">Categorical PMF Parameter'</span>)</span>
<span id="cb6-61"><a href="#cb6-61"></a>    ax.set_xlabel(<span class="st">'Feature 1'</span>)</span>
<span id="cb6-62"><a href="#cb6-62"></a>    ax.set_ylabel(<span class="st">'Feature 2'</span>)</span>
<span id="cb6-63"><a href="#cb6-63"></a>    plt.colorbar(contour, ax<span class="op">=</span>ax)</span>
<span id="cb6-64"><a href="#cb6-64"></a></span>
<span id="cb6-65"><a href="#cb6-65"></a><span class="co"># 5. PMF visualization for specific points</span></span>
<span id="cb6-66"><a href="#cb6-66"></a>sample_points <span class="op">=</span> [(<span class="dv">1</span>, <span class="dv">5</span>), (<span class="dv">3</span>, <span class="dv">3</span>), (<span class="dv">5</span>, <span class="dv">1</span>)]</span>
<span id="cb6-67"><a href="#cb6-67"></a>point_colors <span class="op">=</span> [<span class="st">'purple'</span>, <span class="st">'orange'</span>, <span class="st">'brown'</span>]</span>
<span id="cb6-68"><a href="#cb6-68"></a></span>
<span id="cb6-69"><a href="#cb6-69"></a><span class="cf">for</span> i, (x1_val, x2_val) <span class="kw">in</span> <span class="bu">enumerate</span>(sample_points):</span>
<span id="cb6-70"><a href="#cb6-70"></a>    <span class="co"># Calculate probabilities for this point</span></span>
<span id="cb6-71"><a href="#cb6-71"></a>    point_tensor <span class="op">=</span> torch.tensor([[x1_val, x2_val]], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb6-72"><a href="#cb6-72"></a>    logits_point <span class="op">=</span> torch.matmul(point_tensor, W.T) <span class="op">+</span> b</span>
<span id="cb6-73"><a href="#cb6-73"></a>    probs_point <span class="op">=</span> torch.softmax(logits_point, dim<span class="op">=</span><span class="dv">1</span>).squeeze()</span>
<span id="cb6-74"><a href="#cb6-74"></a>    </span>
<span id="cb6-75"><a href="#cb6-75"></a>    <span class="co"># Plot the categorical PMF for this point</span></span>
<span id="cb6-76"><a href="#cb6-76"></a>    ax <span class="op">=</span> axes[<span class="dv">1</span>, i]</span>
<span id="cb6-77"><a href="#cb6-77"></a>    bars <span class="op">=</span> ax.bar(<span class="bu">range</span>(n_classes), probs_point.numpy(), alpha<span class="op">=</span><span class="fl">0.7</span>, color<span class="op">=</span>point_colors[i])</span>
<span id="cb6-78"><a href="#cb6-78"></a>    ax.set_title(<span class="ss">f'Categorical PMF at (</span><span class="sc">{</span>x1_val<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>x2_val<span class="sc">}</span><span class="ss">)'</span>)</span>
<span id="cb6-79"><a href="#cb6-79"></a>    ax.set_xlabel(<span class="st">'Class'</span>)</span>
<span id="cb6-80"><a href="#cb6-80"></a>    ax.set_ylabel(<span class="st">'Probability'</span>)</span>
<span id="cb6-81"><a href="#cb6-81"></a>    ax.set_ylim(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb6-82"><a href="#cb6-82"></a>    ax.set_xticks(<span class="bu">range</span>(n_classes))</span>
<span id="cb6-83"><a href="#cb6-83"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb6-84"><a href="#cb6-84"></a>    </span>
<span id="cb6-85"><a href="#cb6-85"></a>    <span class="co"># Add probability values on bars</span></span>
<span id="cb6-86"><a href="#cb6-86"></a>    <span class="cf">for</span> j, prob <span class="kw">in</span> <span class="bu">enumerate</span>(probs_point.numpy()):</span>
<span id="cb6-87"><a href="#cb6-87"></a>        ax.text(j, prob <span class="op">+</span> <span class="fl">0.02</span>, <span class="ss">f'</span><span class="sc">{</span>prob<span class="sc">:.3f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb6-88"><a href="#cb6-88"></a>    </span>
<span id="cb6-89"><a href="#cb6-89"></a>    <span class="co"># Mark this point on the main plot</span></span>
<span id="cb6-90"><a href="#cb6-90"></a>    axes[<span class="dv">0</span>, <span class="dv">0</span>].plot(x1_val, x2_val, <span class="st">'o'</span>, color<span class="op">=</span>point_colors[i], markersize<span class="op">=</span><span class="dv">12</span>, </span>
<span id="cb6-91"><a href="#cb6-91"></a>                   markeredgecolor<span class="op">=</span><span class="st">'black'</span>, markeredgewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb6-92"><a href="#cb6-92"></a>    axes[<span class="dv">0</span>, <span class="dv">0</span>].text(x1_val <span class="op">+</span> <span class="fl">0.1</span>, x2_val <span class="op">+</span> <span class="fl">0.1</span>, <span class="ss">f'Point </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>, </span>
<span id="cb6-93"><a href="#cb6-93"></a>                   color<span class="op">=</span>point_colors[i], fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb6-94"><a href="#cb6-94"></a></span>
<span id="cb6-95"><a href="#cb6-95"></a>plt.tight_layout()</span>
<span id="cb6-96"><a href="#cb6-96"></a>plt.show()</span>
<span id="cb6-97"><a href="#cb6-97"></a></span>
<span id="cb6-98"><a href="#cb6-98"></a><span class="co"># Analysis</span></span>
<span id="cb6-99"><a href="#cb6-99"></a><span class="bu">print</span>(<span class="st">"CATEGORICAL DISTRIBUTION ANALYSIS:"</span>)</span>
<span id="cb6-100"><a href="#cb6-100"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb6-101"><a href="#cb6-101"></a></span>
<span id="cb6-102"><a href="#cb6-102"></a><span class="co"># Class distribution</span></span>
<span id="cb6-103"><a href="#cb6-103"></a>class_counts <span class="op">=</span> torch.bincount(Y_multi)</span>
<span id="cb6-104"><a href="#cb6-104"></a><span class="bu">print</span>(<span class="ss">f"Class distribution in sample:"</span>)</span>
<span id="cb6-105"><a href="#cb6-105"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_classes):</span>
<span id="cb6-106"><a href="#cb6-106"></a>    count <span class="op">=</span> class_counts[i].item()</span>
<span id="cb6-107"><a href="#cb6-107"></a>    proportion <span class="op">=</span> count <span class="op">/</span> n_samples</span>
<span id="cb6-108"><a href="#cb6-108"></a>    <span class="bu">print</span>(<span class="ss">f"  Class </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>count<span class="sc">}</span><span class="ss"> samples (</span><span class="sc">{</span>proportion<span class="sc">:.3f}</span><span class="ss">)"</span>)</span>
<span id="cb6-109"><a href="#cb6-109"></a></span>
<span id="cb6-110"><a href="#cb6-110"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">PMF Analysis for sample points:"</span>)</span>
<span id="cb6-111"><a href="#cb6-111"></a><span class="cf">for</span> i, (x1_val, x2_val) <span class="kw">in</span> <span class="bu">enumerate</span>(sample_points):</span>
<span id="cb6-112"><a href="#cb6-112"></a>    point_tensor <span class="op">=</span> torch.tensor([[x1_val, x2_val]], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb6-113"><a href="#cb6-113"></a>    logits_point <span class="op">=</span> torch.matmul(point_tensor, W.T) <span class="op">+</span> b</span>
<span id="cb6-114"><a href="#cb6-114"></a>    probs_point <span class="op">=</span> torch.softmax(logits_point, dim<span class="op">=</span><span class="dv">1</span>).squeeze()</span>
<span id="cb6-115"><a href="#cb6-115"></a>    </span>
<span id="cb6-116"><a href="#cb6-116"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Point </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: (</span><span class="sc">{</span>x1_val<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>x2_val<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb6-117"><a href="#cb6-117"></a>    <span class="bu">print</span>(<span class="ss">f"  Logits: </span><span class="sc">{</span>logits_point<span class="sc">.</span>squeeze()<span class="sc">.</span>numpy()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-118"><a href="#cb6-118"></a>    <span class="bu">print</span>(<span class="ss">f"  Probabilities: </span><span class="sc">{</span>probs_point<span class="sc">.</span>numpy()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-119"><a href="#cb6-119"></a>    <span class="bu">print</span>(<span class="ss">f"  Predicted class: </span><span class="sc">{</span>torch<span class="sc">.</span>argmax(probs_point)<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-120"><a href="#cb6-120"></a>    <span class="bu">print</span>(<span class="ss">f"  Confidence: </span><span class="sc">{</span>torch<span class="sc">.</span><span class="bu">max</span>(probs_point)<span class="sc">.</span>item()<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb6-121"><a href="#cb6-121"></a></span>
<span id="cb6-122"><a href="#cb6-122"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Key Properties Verified:"</span>)</span>
<span id="cb6-123"><a href="#cb6-123"></a><span class="bu">print</span>(<span class="ss">f"- Non-negativity: All probabilities ≥ 0 ✓"</span>)</span>
<span id="cb6-124"><a href="#cb6-124"></a><span class="bu">print</span>(<span class="ss">f"- Normalization: Each point's probabilities sum to 1 ✓"</span>)</span>
<span id="cb6-125"><a href="#cb6-125"></a><span class="bu">print</span>(<span class="ss">f"- Mutual exclusivity: Each sample belongs to exactly one class ✓"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="example-3-multinomial-and-categorical-distributions" class="level2">
<h2 class="anchored" data-anchor-id="example-3-multinomial-and-categorical-distributions">Example 3: Multinomial and Categorical Distributions</h2>
<p>PMFs extend beyond binary outcomes. Let’s explore the Categorical distribution, which generalizes the Bernoulli to multiple classes.</p>
<div id="cell-15" class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="co"># Demonstrate the connection to Maximum Likelihood Estimation</span></span>
<span id="cb7-2"><a href="#cb7-2"></a><span class="kw">def</span> bernoulli_likelihood(y_true, p_pred):</span>
<span id="cb7-3"><a href="#cb7-3"></a>    <span class="co">"""</span></span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="co">    Compute the likelihood of data under Bernoulli model</span></span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="co">    L = ∏ᵢ p_i^{y_i} (1-p_i)^{1-y_i}</span></span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="co">    """</span></span>
<span id="cb7-7"><a href="#cb7-7"></a>    likelihood <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb7-8"><a href="#cb7-8"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(y_true)):</span>
<span id="cb7-9"><a href="#cb7-9"></a>        <span class="cf">if</span> y_true[i] <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb7-10"><a href="#cb7-10"></a>            likelihood <span class="op">*=</span> p_pred[i]</span>
<span id="cb7-11"><a href="#cb7-11"></a>        <span class="cf">else</span>:</span>
<span id="cb7-12"><a href="#cb7-12"></a>            likelihood <span class="op">*=</span> (<span class="dv">1</span> <span class="op">-</span> p_pred[i])</span>
<span id="cb7-13"><a href="#cb7-13"></a>    <span class="cf">return</span> likelihood</span>
<span id="cb7-14"><a href="#cb7-14"></a></span>
<span id="cb7-15"><a href="#cb7-15"></a><span class="kw">def</span> log_likelihood(y_true, p_pred):</span>
<span id="cb7-16"><a href="#cb7-16"></a>    <span class="co">"""</span></span>
<span id="cb7-17"><a href="#cb7-17"></a><span class="co">    Compute log-likelihood (more numerically stable)</span></span>
<span id="cb7-18"><a href="#cb7-18"></a><span class="co">    ℓ = Σᵢ [y_i log(p_i) + (1-y_i) log(1-p_i)]</span></span>
<span id="cb7-19"><a href="#cb7-19"></a><span class="co">    """</span></span>
<span id="cb7-20"><a href="#cb7-20"></a>    ll <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb7-21"><a href="#cb7-21"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(y_true)):</span>
<span id="cb7-22"><a href="#cb7-22"></a>        <span class="cf">if</span> y_true[i] <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb7-23"><a href="#cb7-23"></a>            ll <span class="op">+=</span> np.log(p_pred[i] <span class="op">+</span> <span class="fl">1e-15</span>)  <span class="co"># Add small epsilon to avoid log(0)</span></span>
<span id="cb7-24"><a href="#cb7-24"></a>        <span class="cf">else</span>:</span>
<span id="cb7-25"><a href="#cb7-25"></a>            ll <span class="op">+=</span> np.log(<span class="dv">1</span> <span class="op">-</span> p_pred[i] <span class="op">+</span> <span class="fl">1e-15</span>)</span>
<span id="cb7-26"><a href="#cb7-26"></a>    <span class="cf">return</span> ll</span>
<span id="cb7-27"><a href="#cb7-27"></a></span>
<span id="cb7-28"><a href="#cb7-28"></a><span class="co"># Analyze likelihood for different parameter settings</span></span>
<span id="cb7-29"><a href="#cb7-29"></a>Y_sample <span class="op">=</span> Y[:<span class="dv">100</span>]  <span class="co"># Use subset for clearer visualization</span></span>
<span id="cb7-30"><a href="#cb7-30"></a>X1_sample <span class="op">=</span> X1[:<span class="dv">100</span>]</span>
<span id="cb7-31"><a href="#cb7-31"></a>X2_sample <span class="op">=</span> X2[:<span class="dv">100</span>]</span>
<span id="cb7-32"><a href="#cb7-32"></a></span>
<span id="cb7-33"><a href="#cb7-33"></a><span class="co"># Test different parameter settings</span></span>
<span id="cb7-34"><a href="#cb7-34"></a>test_scenarios <span class="op">=</span> [</span>
<span id="cb7-35"><a href="#cb7-35"></a>    {<span class="st">"name"</span>: <span class="st">"True Parameters"</span>, <span class="st">"w1"</span>: w1, <span class="st">"w2"</span>: w2, <span class="st">"b"</span>: b},</span>
<span id="cb7-36"><a href="#cb7-36"></a>    {<span class="st">"name"</span>: <span class="st">"Random Guess 1"</span>, <span class="st">"w1"</span>: <span class="fl">0.5</span>, <span class="st">"w2"</span>: <span class="op">-</span><span class="fl">0.3</span>, <span class="st">"b"</span>: <span class="op">-</span><span class="fl">1.0</span>},</span>
<span id="cb7-37"><a href="#cb7-37"></a>    {<span class="st">"name"</span>: <span class="st">"Random Guess 2"</span>, <span class="st">"w1"</span>: <span class="op">-</span><span class="fl">0.8</span>, <span class="st">"w2"</span>: <span class="fl">1.2</span>, <span class="st">"b"</span>: <span class="fl">1.5</span>},</span>
<span id="cb7-38"><a href="#cb7-38"></a>    {<span class="st">"name"</span>: <span class="st">"Poor Fit"</span>, <span class="st">"w1"</span>: <span class="fl">0.1</span>, <span class="st">"w2"</span>: <span class="fl">0.1</span>, <span class="st">"b"</span>: <span class="fl">0.0</span>}</span>
<span id="cb7-39"><a href="#cb7-39"></a>]</span>
<span id="cb7-40"><a href="#cb7-40"></a></span>
<span id="cb7-41"><a href="#cb7-41"></a>results <span class="op">=</span> []</span>
<span id="cb7-42"><a href="#cb7-42"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">12</span>))</span>
<span id="cb7-43"><a href="#cb7-43"></a>axes <span class="op">=</span> axes.ravel()</span>
<span id="cb7-44"><a href="#cb7-44"></a></span>
<span id="cb7-45"><a href="#cb7-45"></a><span class="cf">for</span> i, scenario <span class="kw">in</span> <span class="bu">enumerate</span>(test_scenarios):</span>
<span id="cb7-46"><a href="#cb7-46"></a>    <span class="co"># Compute predictions</span></span>
<span id="cb7-47"><a href="#cb7-47"></a>    logits_test <span class="op">=</span> scenario[<span class="st">"w1"</span>] <span class="op">*</span> X1_sample <span class="op">+</span> scenario[<span class="st">"w2"</span>] <span class="op">*</span> X2_sample <span class="op">+</span> scenario[<span class="st">"b"</span>]</span>
<span id="cb7-48"><a href="#cb7-48"></a>    p_test <span class="op">=</span> torch.sigmoid(logits_test).numpy()</span>
<span id="cb7-49"><a href="#cb7-49"></a>    </span>
<span id="cb7-50"><a href="#cb7-50"></a>    <span class="co"># Compute likelihood metrics</span></span>
<span id="cb7-51"><a href="#cb7-51"></a>    likelihood <span class="op">=</span> bernoulli_likelihood(Y_sample.numpy(), p_test)</span>
<span id="cb7-52"><a href="#cb7-52"></a>    log_ll <span class="op">=</span> log_likelihood(Y_sample.numpy(), p_test)</span>
<span id="cb7-53"><a href="#cb7-53"></a>    </span>
<span id="cb7-54"><a href="#cb7-54"></a>    results.append({</span>
<span id="cb7-55"><a href="#cb7-55"></a>        <span class="st">"scenario"</span>: scenario[<span class="st">"name"</span>],</span>
<span id="cb7-56"><a href="#cb7-56"></a>        <span class="st">"likelihood"</span>: likelihood,</span>
<span id="cb7-57"><a href="#cb7-57"></a>        <span class="st">"log_likelihood"</span>: log_ll,</span>
<span id="cb7-58"><a href="#cb7-58"></a>        <span class="st">"parameters"</span>: (scenario[<span class="st">"w1"</span>], scenario[<span class="st">"w2"</span>], scenario[<span class="st">"b"</span>])</span>
<span id="cb7-59"><a href="#cb7-59"></a>    })</span>
<span id="cb7-60"><a href="#cb7-60"></a>    </span>
<span id="cb7-61"><a href="#cb7-61"></a>    <span class="co"># Visualize decision boundary</span></span>
<span id="cb7-62"><a href="#cb7-62"></a>    ax <span class="op">=</span> axes[i]</span>
<span id="cb7-63"><a href="#cb7-63"></a>    </span>
<span id="cb7-64"><a href="#cb7-64"></a>    <span class="co"># Plot data points</span></span>
<span id="cb7-65"><a href="#cb7-65"></a>    Y_sample_np <span class="op">=</span> Y_sample.numpy()</span>
<span id="cb7-66"><a href="#cb7-66"></a>    ax.scatter(X1_sample[Y_sample_np <span class="op">==</span> <span class="dv">0</span>], X2_sample[Y_sample_np <span class="op">==</span> <span class="dv">0</span>], </span>
<span id="cb7-67"><a href="#cb7-67"></a>              color<span class="op">=</span><span class="st">"blue"</span>, label<span class="op">=</span><span class="st">"Class 0"</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb7-68"><a href="#cb7-68"></a>    ax.scatter(X1_sample[Y_sample_np <span class="op">==</span> <span class="dv">1</span>], X2_sample[Y_sample_np <span class="op">==</span> <span class="dv">1</span>], </span>
<span id="cb7-69"><a href="#cb7-69"></a>              color<span class="op">=</span><span class="st">"red"</span>, label<span class="op">=</span><span class="st">"Class 1"</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb7-70"><a href="#cb7-70"></a>    </span>
<span id="cb7-71"><a href="#cb7-71"></a>    <span class="co"># Plot decision boundary</span></span>
<span id="cb7-72"><a href="#cb7-72"></a>    x1_range <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">100</span>)</span>
<span id="cb7-73"><a href="#cb7-73"></a>    <span class="cf">if</span> scenario[<span class="st">"w2"</span>] <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb7-74"><a href="#cb7-74"></a>        x2_boundary <span class="op">=</span> <span class="op">-</span>(scenario[<span class="st">"w1"</span>] <span class="op">*</span> x1_range <span class="op">+</span> scenario[<span class="st">"b"</span>]) <span class="op">/</span> scenario[<span class="st">"w2"</span>]</span>
<span id="cb7-75"><a href="#cb7-75"></a>        valid_mask <span class="op">=</span> (x2_boundary <span class="op">&gt;=</span> <span class="dv">0</span>) <span class="op">&amp;</span> (x2_boundary <span class="op">&lt;=</span> <span class="dv">5</span>)</span>
<span id="cb7-76"><a href="#cb7-76"></a>        ax.plot(x1_range[valid_mask], x2_boundary[valid_mask], <span class="st">'k-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, </span>
<span id="cb7-77"><a href="#cb7-77"></a>               label<span class="op">=</span><span class="st">'Decision Boundary'</span>)</span>
<span id="cb7-78"><a href="#cb7-78"></a>    </span>
<span id="cb7-79"><a href="#cb7-79"></a>    ax.set_title(<span class="ss">f'</span><span class="sc">{</span>scenario[<span class="st">"name"</span>]<span class="sc">}</span><span class="ch">\n</span><span class="ss">Log-Likelihood: </span><span class="sc">{</span>log_ll<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb7-80"><a href="#cb7-80"></a>    ax.set_xlabel(<span class="st">'Feature 1 (X₁)'</span>)</span>
<span id="cb7-81"><a href="#cb7-81"></a>    ax.set_ylabel(<span class="st">'Feature 2 (X₂)'</span>)</span>
<span id="cb7-82"><a href="#cb7-82"></a>    ax.legend()</span>
<span id="cb7-83"><a href="#cb7-83"></a>    ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb7-84"><a href="#cb7-84"></a>    ax.set_xlim(<span class="dv">0</span>, <span class="dv">5</span>)</span>
<span id="cb7-85"><a href="#cb7-85"></a>    ax.set_ylim(<span class="dv">0</span>, <span class="dv">5</span>)</span>
<span id="cb7-86"><a href="#cb7-86"></a></span>
<span id="cb7-87"><a href="#cb7-87"></a>plt.tight_layout()</span>
<span id="cb7-88"><a href="#cb7-88"></a>plt.show()</span>
<span id="cb7-89"><a href="#cb7-89"></a></span>
<span id="cb7-90"><a href="#cb7-90"></a><span class="co"># Print detailed results</span></span>
<span id="cb7-91"><a href="#cb7-91"></a><span class="bu">print</span>(<span class="st">"MAXIMUM LIKELIHOOD ESTIMATION RESULTS:"</span>)</span>
<span id="cb7-92"><a href="#cb7-92"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">60</span>)</span>
<span id="cb7-93"><a href="#cb7-93"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Scenario'</span><span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Log-Likelihood'</span><span class="sc">:&lt;15}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Likelihood'</span><span class="sc">:&lt;15}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Parameters (w1, w2, b)'</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-94"><a href="#cb7-94"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">80</span>)</span>
<span id="cb7-95"><a href="#cb7-95"></a></span>
<span id="cb7-96"><a href="#cb7-96"></a><span class="co"># Sort by log-likelihood (higher is better)</span></span>
<span id="cb7-97"><a href="#cb7-97"></a>results.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">'log_likelihood'</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-98"><a href="#cb7-98"></a></span>
<span id="cb7-99"><a href="#cb7-99"></a><span class="cf">for</span> result <span class="kw">in</span> results:</span>
<span id="cb7-100"><a href="#cb7-100"></a>    ll <span class="op">=</span> result[<span class="st">'log_likelihood'</span>]</span>
<span id="cb7-101"><a href="#cb7-101"></a>    likelihood <span class="op">=</span> result[<span class="st">'likelihood'</span>]</span>
<span id="cb7-102"><a href="#cb7-102"></a>    params <span class="op">=</span> result[<span class="st">'parameters'</span>]</span>
<span id="cb7-103"><a href="#cb7-103"></a>    scenario <span class="op">=</span> result[<span class="st">'scenario'</span>]</span>
<span id="cb7-104"><a href="#cb7-104"></a>    </span>
<span id="cb7-105"><a href="#cb7-105"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>scenario<span class="sc">:&lt;20}</span><span class="ss"> </span><span class="sc">{</span>ll<span class="sc">:&lt;15.3f}</span><span class="ss"> </span><span class="sc">{</span>likelihood<span class="sc">:&lt;15.2e}</span><span class="ss"> </span><span class="sc">{</span>params<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-106"><a href="#cb7-106"></a></span>
<span id="cb7-107"><a href="#cb7-107"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">KEY INSIGHTS:"</span>)</span>
<span id="cb7-108"><a href="#cb7-108"></a><span class="bu">print</span>(<span class="ss">f"- Higher likelihood = better fit to the data"</span>)</span>
<span id="cb7-109"><a href="#cb7-109"></a><span class="bu">print</span>(<span class="ss">f"- Log-likelihood is used for numerical stability"</span>)</span>
<span id="cb7-110"><a href="#cb7-110"></a><span class="bu">print</span>(<span class="ss">f"- True parameters achieve highest likelihood (as expected)"</span>)</span>
<span id="cb7-111"><a href="#cb7-111"></a><span class="bu">print</span>(<span class="ss">f"- Poor parameters result in low likelihood"</span>)</span>
<span id="cb7-112"><a href="#cb7-112"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">The learning algorithm finds parameters that maximize:"</span>)</span>
<span id="cb7-113"><a href="#cb7-113"></a><span class="bu">print</span>(<span class="ss">f"  ℓ = Σᵢ [yᵢ log(pᵢ) + (1-yᵢ) log(1-pᵢ)]"</span>)</span>
<span id="cb7-114"><a href="#cb7-114"></a><span class="bu">print</span>(<span class="ss">f"where pᵢ = σ(w₁x₁ᵢ + w₂x₂ᵢ + b) is the Bernoulli parameter"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-16" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a></span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="co"># Generate 2D input features</span></span>
<span id="cb8-3"><a href="#cb8-3"></a>n_samples <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb8-4"><a href="#cb8-4"></a>X1 <span class="op">=</span> torch.distributions.Uniform(<span class="dv">0</span>, <span class="dv">5</span>).sample((n_samples, <span class="dv">1</span>))  <span class="co"># Feature 1</span></span>
<span id="cb8-5"><a href="#cb8-5"></a>X2 <span class="op">=</span> torch.distributions.Uniform(<span class="dv">0</span>, <span class="dv">5</span>).sample((n_samples, <span class="dv">1</span>))  <span class="co"># Feature 2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-17" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="co"># True weights and bias</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>w1, w2, b <span class="op">=</span> <span class="fl">1.2</span>, <span class="op">-</span><span class="fl">0.8</span>, <span class="op">-</span><span class="fl">2.5</span>  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-18" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># Compute logits and apply sigmoid</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>logits <span class="op">=</span> w1 <span class="op">*</span> X1 <span class="op">+</span> w2 <span class="op">*</span> X2 <span class="op">+</span> b</span>
<span id="cb10-3"><a href="#cb10-3"></a>prob_Y <span class="op">=</span> torch.sigmoid(logits)  <span class="co"># Probabilities</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-19" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a>prob_Y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor([[0.4690],
        [0.8697],
        [0.2377],
        [0.6852],
        [0.2472],
        [0.5074],
        [0.0922],
        [0.7336],
        [0.8787],
        [0.0406],
        [0.6429],
        [0.6637],
        [0.8729],
        [0.2455],
        [0.4179],
        [0.0462],
        [0.9018],
        [0.1551],
        [0.0173],
        [0.1364],
        [0.2652],
        [0.2519],
        [0.2691],
        [0.8527],
        [0.0068],
        [0.0701],
        [0.0393],
        [0.1062],
        [0.1793],
        [0.0372],
        [0.5522],
        [0.0402],
        [0.7888],
        [0.6758],
        [0.0772],
        [0.1758],
        [0.1189],
        [0.8798],
        [0.2317],
        [0.0974],
        [0.7143],
        [0.0202],
        [0.4330],
        [0.6808],
        [0.7392],
        [0.1329],
        [0.4755],
        [0.1541],
        [0.3953],
        [0.0859],
        [0.0016],
        [0.0859],
        [0.0707],
        [0.8696],
        [0.0688],
        [0.4360],
        [0.4305],
        [0.3274],
        [0.7977],
        [0.1249],
        [0.5691],
        [0.0089],
        [0.0923],
        [0.0116],
        [0.7033],
        [0.0389],
        [0.9026],
        [0.0113],
        [0.0087],
        [0.0079],
        [0.4398],
        [0.1479],
        [0.7938],
        [0.0074],
        [0.0228],
        [0.0089],
        [0.0534],
        [0.4375],
        [0.7883],
        [0.8199],
        [0.1195],
        [0.0536],
        [0.7972],
        [0.2862],
        [0.5475],
        [0.0290],
        [0.1672],
        [0.0067],
        [0.1216],
        [0.8010],
        [0.1646],
        [0.0328],
        [0.8813],
        [0.4557],
        [0.0046],
        [0.0383],
        [0.9207],
        [0.0155],
        [0.0318],
        [0.0032],
        [0.1341],
        [0.1285],
        [0.3706],
        [0.0035],
        [0.3584],
        [0.0085],
        [0.0116],
        [0.0246],
        [0.0215],
        [0.0143],
        [0.9115],
        [0.7215],
        [0.5481],
        [0.0028],
        [0.0500],
        [0.0420],
        [0.4277],
        [0.0035],
        [0.0182],
        [0.0180],
        [0.3848],
        [0.2725],
        [0.1439],
        [0.0863],
        [0.0055],
        [0.2094],
        [0.0317],
        [0.0028],
        [0.5034],
        [0.0586],
        [0.9528],
        [0.0766],
        [0.0242],
        [0.9202],
        [0.0134],
        [0.1375],
        [0.0209],
        [0.0018],
        [0.6780],
        [0.3229],
        [0.3414],
        [0.0243],
        [0.5663],
        [0.1166],
        [0.1113],
        [0.5040],
        [0.7373],
        [0.9401],
        [0.5430],
        [0.0139],
        [0.7203],
        [0.0124],
        [0.0808],
        [0.0160],
        [0.9173],
        [0.0179],
        [0.1390],
        [0.1397],
        [0.7374],
        [0.0071],
        [0.7449],
        [0.1415],
        [0.0649],
        [0.0029],
        [0.7889],
        [0.0241],
        [0.1800],
        [0.7164],
        [0.6379],
        [0.0617],
        [0.0508],
        [0.1972],
        [0.6204],
        [0.0813],
        [0.0056],
        [0.0244],
        [0.0077],
        [0.2261],
        [0.3260],
        [0.0143],
        [0.2764],
        [0.4105],
        [0.6875],
        [0.2774],
        [0.4553],
        [0.7025],
        [0.4154],
        [0.1725],
        [0.0688],
        [0.0773],
        [0.2032],
        [0.0181],
        [0.2384],
        [0.9317],
        [0.4372],
        [0.3650],
        [0.4109],
        [0.2889],
        [0.3479],
        [0.4569],
        [0.0386],
        [0.1222],
        [0.8519],
        [0.0917],
        [0.2874],
        [0.1328],
        [0.0153],
        [0.0168],
        [0.0178],
        [0.1498],
        [0.1939],
        [0.7941],
        [0.0043],
        [0.0068],
        [0.2717],
        [0.3926],
        [0.0714],
        [0.0912],
        [0.2274],
        [0.1253],
        [0.1548],
        [0.5459],
        [0.0305],
        [0.3112],
        [0.0043],
        [0.9017],
        [0.2792],
        [0.0876],
        [0.0157],
        [0.0389],
        [0.0073],
        [0.5978],
        [0.3535],
        [0.5908],
        [0.1898],
        [0.5297],
        [0.2536],
        [0.0130],
        [0.0135],
        [0.0027],
        [0.6854],
        [0.0522],
        [0.0775],
        [0.0632],
        [0.0320],
        [0.0212],
        [0.1663],
        [0.4284],
        [0.1848],
        [0.5393],
        [0.0971],
        [0.1523],
        [0.1591],
        [0.0594],
        [0.1385],
        [0.0020],
        [0.6491],
        [0.0076],
        [0.3805],
        [0.8249],
        [0.5432],
        [0.0042],
        [0.8772],
        [0.1644],
        [0.0875],
        [0.4281],
        [0.3085],
        [0.0614],
        [0.1262],
        [0.1158],
        [0.4476],
        [0.0059],
        [0.7236],
        [0.5122],
        [0.9547],
        [0.0268],
        [0.0034],
        [0.1269],
        [0.4547],
        [0.0058],
        [0.3243],
        [0.0574],
        [0.1720],
        [0.1343],
        [0.2229],
        [0.0219],
        [0.0033],
        [0.9415],
        [0.5935],
        [0.0582],
        [0.0232],
        [0.0202],
        [0.0024],
        [0.0227],
        [0.1436],
        [0.0084],
        [0.1765],
        [0.4679],
        [0.0520],
        [0.0276],
        [0.3989],
        [0.0865],
        [0.0738],
        [0.0310],
        [0.0538],
        [0.4719],
        [0.0175],
        [0.6643],
        [0.0717],
        [0.2207],
        [0.6581],
        [0.1212],
        [0.0091],
        [0.5362],
        [0.3897],
        [0.5126],
        [0.7488],
        [0.7894],
        [0.3925],
        [0.2507],
        [0.0973],
        [0.0892],
        [0.6295],
        [0.4406],
        [0.1529],
        [0.1186],
        [0.0113],
        [0.0021],
        [0.1150],
        [0.0482],
        [0.8805],
        [0.2454],
        [0.0035],
        [0.0044],
        [0.8107],
        [0.0069],
        [0.0515],
        [0.4856],
        [0.0080],
        [0.2625],
        [0.2149],
        [0.2317],
        [0.0353],
        [0.0090],
        [0.0166],
        [0.1212],
        [0.9087],
        [0.0258],
        [0.1467],
        [0.3867],
        [0.3478],
        [0.7219],
        [0.5131],
        [0.5104],
        [0.0028],
        [0.2580],
        [0.8291],
        [0.0395],
        [0.0280],
        [0.8736],
        [0.2135],
        [0.0247],
        [0.0914],
        [0.1309],
        [0.2388],
        [0.7147],
        [0.5993],
        [0.0881],
        [0.0025],
        [0.0412],
        [0.7522],
        [0.1615],
        [0.0706],
        [0.5131],
        [0.0120],
        [0.0252],
        [0.0513],
        [0.5335],
        [0.3664],
        [0.0042],
        [0.2806],
        [0.1637],
        [0.1168],
        [0.9396],
        [0.0373],
        [0.7879],
        [0.0925],
        [0.0391],
        [0.6586],
        [0.4116],
        [0.1996],
        [0.0494],
        [0.2710],
        [0.6425],
        [0.1510],
        [0.0312],
        [0.0179],
        [0.1739],
        [0.6685],
        [0.2275],
        [0.1530],
        [0.9160],
        [0.4186],
        [0.1890],
        [0.2847],
        [0.0327],
        [0.0187],
        [0.0628],
        [0.1278],
        [0.3404],
        [0.1098],
        [0.0375],
        [0.7807],
        [0.6327],
        [0.7904],
        [0.0507],
        [0.1858],
        [0.3649],
        [0.0336],
        [0.0142],
        [0.1073],
        [0.0164],
        [0.0245],
        [0.8529],
        [0.5046],
        [0.5838],
        [0.1484],
        [0.0258],
        [0.1378],
        [0.5009],
        [0.1275],
        [0.0463],
        [0.0377],
        [0.1537],
        [0.1114],
        [0.5183],
        [0.0190],
        [0.0583],
        [0.3773],
        [0.1361],
        [0.2197],
        [0.6813],
        [0.2385],
        [0.9250],
        [0.9642],
        [0.1617],
        [0.0100],
        [0.4980],
        [0.9302],
        [0.0457],
        [0.1462],
        [0.0613],
        [0.0062],
        [0.0611],
        [0.2581],
        [0.6507],
        [0.0583],
        [0.6322],
        [0.0657],
        [0.0992],
        [0.5305],
        [0.1600],
        [0.3603],
        [0.0488],
        [0.6136],
        [0.1191],
        [0.0036],
        [0.0577],
        [0.4877],
        [0.3272],
        [0.7177],
        [0.4588],
        [0.7115],
        [0.0364],
        [0.2061],
        [0.3108],
        [0.0613],
        [0.0117],
        [0.0795],
        [0.4676],
        [0.5647],
        [0.0231],
        [0.1328],
        [0.5421],
        [0.0562],
        [0.0614],
        [0.3270],
        [0.0339],
        [0.8109],
        [0.3840],
        [0.5580],
        [0.6581],
        [0.5215],
        [0.4812],
        [0.4216],
        [0.5801],
        [0.8010],
        [0.6829],
        [0.0294],
        [0.0095],
        [0.0193],
        [0.0555],
        [0.2013],
        [0.8739],
        [0.5182],
        [0.8575],
        [0.0095],
        [0.0300],
        [0.0588],
        [0.0581],
        [0.4170],
        [0.0025],
        [0.1793],
        [0.0060],
        [0.0250],
        [0.0052],
        [0.4422],
        [0.0052],
        [0.3186],
        [0.2248],
        [0.0405],
        [0.4789],
        [0.0483],
        [0.1727],
        [0.5538],
        [0.0335],
        [0.4634],
        [0.1829],
        [0.2329],
        [0.3739],
        [0.0957],
        [0.0156],
        [0.3449],
        [0.8196],
        [0.6699],
        [0.4111],
        [0.0098],
        [0.3198],
        [0.0751],
        [0.8296],
        [0.0686],
        [0.0258],
        [0.0505],
        [0.0505],
        [0.6845],
        [0.1587],
        [0.3579],
        [0.6190],
        [0.9235],
        [0.2053],
        [0.1562],
        [0.4789],
        [0.0443],
        [0.2962],
        [0.0232],
        [0.0190],
        [0.5996],
        [0.6140],
        [0.7862],
        [0.9355],
        [0.4863],
        [0.5655],
        [0.0436],
        [0.0308],
        [0.0309],
        [0.0590],
        [0.0157],
        [0.0254],
        [0.0145],
        [0.0126],
        [0.0280],
        [0.0055],
        [0.0610],
        [0.6977],
        [0.6296],
        [0.1038],
        [0.1875],
        [0.3234],
        [0.0475],
        [0.0674],
        [0.7886],
        [0.0208],
        [0.6382],
        [0.6671],
        [0.2659],
        [0.1304],
        [0.0330],
        [0.1543],
        [0.1324],
        [0.0923],
        [0.6481],
        [0.4782],
        [0.0137],
        [0.4810],
        [0.0242],
        [0.0645],
        [0.2477],
        [0.0396],
        [0.8759],
        [0.0614],
        [0.2093],
        [0.2825],
        [0.0732],
        [0.0819],
        [0.0994],
        [0.0042],
        [0.0639],
        [0.0714],
        [0.6146],
        [0.5548],
        [0.5720],
        [0.0173],
        [0.0950],
        [0.9247],
        [0.0979],
        [0.5093],
        [0.3201],
        [0.0249],
        [0.0115],
        [0.8606],
        [0.3280],
        [0.2417],
        [0.0065],
        [0.0185],
        [0.0386],
        [0.0495],
        [0.0566],
        [0.8324],
        [0.0054],
        [0.1783],
        [0.0084],
        [0.1398],
        [0.5463],
        [0.5990],
        [0.2893],
        [0.2422],
        [0.0921],
        [0.0408],
        [0.0046],
        [0.0630],
        [0.2670],
        [0.0066],
        [0.9150],
        [0.5427],
        [0.0191],
        [0.1254],
        [0.0957],
        [0.3615],
        [0.1072],
        [0.2503],
        [0.7266],
        [0.0921],
        [0.5816],
        [0.4543],
        [0.1018],
        [0.9215],
        [0.0393],
        [0.1537],
        [0.0449],
        [0.8551],
        [0.0236],
        [0.3884],
        [0.0032],
        [0.3583],
        [0.7975],
        [0.1741],
        [0.7627],
        [0.0478],
        [0.4580],
        [0.0336],
        [0.2849],
        [0.2970],
        [0.9362],
        [0.2849],
        [0.0084],
        [0.3964],
        [0.0635],
        [0.4038],
        [0.0035],
        [0.2056],
        [0.7709],
        [0.2959],
        [0.0089],
        [0.1077],
        [0.0589],
        [0.5707],
        [0.0962],
        [0.0793],
        [0.0674],
        [0.0335],
        [0.7049],
        [0.8910],
        [0.0836],
        [0.3845],
        [0.5714],
        [0.7929],
        [0.6587],
        [0.5552],
        [0.0545],
        [0.8679],
        [0.8363],
        [0.0228],
        [0.0075],
        [0.0453],
        [0.1558],
        [0.0073],
        [0.1370],
        [0.4195],
        [0.0152],
        [0.1042],
        [0.0471],
        [0.1086],
        [0.6888],
        [0.0051],
        [0.4637],
        [0.9148],
        [0.3310],
        [0.0220],
        [0.0207],
        [0.1868],
        [0.0823],
        [0.2680],
        [0.8058],
        [0.9286],
        [0.1681],
        [0.1451],
        [0.1451],
        [0.0671],
        [0.0082],
        [0.1195],
        [0.8149],
        [0.0024],
        [0.0062],
        [0.6743],
        [0.4562],
        [0.6410],
        [0.0143],
        [0.0469],
        [0.7715],
        [0.4464],
        [0.5066],
        [0.1339],
        [0.5612],
        [0.5935],
        [0.0075],
        [0.0167],
        [0.5136],
        [0.0040],
        [0.0411],
        [0.5657],
        [0.0792],
        [0.0777],
        [0.1271],
        [0.0341],
        [0.6242],
        [0.0441],
        [0.0383],
        [0.7237],
        [0.0076],
        [0.3616],
        [0.1653],
        [0.2611],
        [0.4183],
        [0.0433],
        [0.0674],
        [0.7030],
        [0.2125],
        [0.0033],
        [0.0105],
        [0.5878],
        [0.2345],
        [0.7199],
        [0.1536],
        [0.0522],
        [0.0208],
        [0.1033],
        [0.0328],
        [0.5261],
        [0.4477],
        [0.4163],
        [0.0638],
        [0.0860],
        [0.7403],
        [0.3582],
        [0.0382],
        [0.0144],
        [0.3440],
        [0.1347],
        [0.2414],
        [0.9490],
        [0.0595],
        [0.9154],
        [0.8628],
        [0.0031],
        [0.6427],
        [0.0366],
        [0.0776],
        [0.3921],
        [0.0062],
        [0.8658],
        [0.2734],
        [0.7700],
        [0.0047],
        [0.6233],
        [0.0978],
        [0.0369],
        [0.4760],
        [0.4007],
        [0.3911],
        [0.1022],
        [0.0443],
        [0.6452],
        [0.5626],
        [0.1089],
        [0.5314],
        [0.0162],
        [0.6265],
        [0.8584],
        [0.2519],
        [0.2426],
        [0.8181],
        [0.5241],
        [0.0241],
        [0.0273],
        [0.0294],
        [0.3048],
        [0.2815],
        [0.1653],
        [0.6694],
        [0.0173],
        [0.4302],
        [0.2016],
        [0.0251],
        [0.1268],
        [0.0075],
        [0.5129],
        [0.0309],
        [0.0977],
        [0.0888],
        [0.1067],
        [0.5135],
        [0.0031],
        [0.0084],
        [0.0379],
        [0.3944],
        [0.0491],
        [0.1070],
        [0.0736],
        [0.1812],
        [0.9447],
        [0.1928],
        [0.1918],
        [0.0043],
        [0.1300],
        [0.0261],
        [0.1692],
        [0.8610],
        [0.8094],
        [0.9622],
        [0.5234],
        [0.1729],
        [0.0978],
        [0.5527],
        [0.0086],
        [0.2799],
        [0.3916],
        [0.6266],
        [0.3144],
        [0.0426],
        [0.0029],
        [0.0657],
        [0.4495],
        [0.1725],
        [0.1724],
        [0.4098],
        [0.0512],
        [0.8470],
        [0.1267],
        [0.5247],
        [0.1115],
        [0.7646],
        [0.7213],
        [0.0759],
        [0.3569],
        [0.3375],
        [0.8672],
        [0.7596],
        [0.1475],
        [0.0044],
        [0.4780],
        [0.0581],
        [0.0251],
        [0.4568],
        [0.2024],
        [0.7446],
        [0.6320],
        [0.0314],
        [0.0765],
        [0.0181],
        [0.1966],
        [0.5667],
        [0.8577],
        [0.9013],
        [0.1643],
        [0.0776],
        [0.1805],
        [0.0631],
        [0.1894],
        [0.3725],
        [0.0367],
        [0.1032],
        [0.8510],
        [0.3935],
        [0.8488],
        [0.9634],
        [0.0439],
        [0.0918],
        [0.5004],
        [0.0232],
        [0.2922],
        [0.0592],
        [0.6902],
        [0.0502],
        [0.2931],
        [0.5467],
        [0.0902],
        [0.0438],
        [0.7579],
        [0.0144],
        [0.0310],
        [0.9566],
        [0.0983],
        [0.1246],
        [0.0175],
        [0.3579],
        [0.1215],
        [0.0063],
        [0.8350],
        [0.0783],
        [0.0673],
        [0.0044],
        [0.1932],
        [0.0166],
        [0.0619],
        [0.0126],
        [0.0981],
        [0.1415],
        [0.0975],
        [0.0028],
        [0.7217],
        [0.1342],
        [0.0666],
        [0.8163],
        [0.5906],
        [0.8264],
        [0.0062],
        [0.1267],
        [0.0576],
        [0.4529],
        [0.1712],
        [0.0178],
        [0.1451],
        [0.0375],
        [0.1448],
        [0.1852],
        [0.9204],
        [0.6197],
        [0.0180],
        [0.3411],
        [0.0445],
        [0.1539],
        [0.4608],
        [0.5943],
        [0.2118],
        [0.8577],
        [0.0662],
        [0.2722],
        [0.6509],
        [0.5460],
        [0.4635],
        [0.2292],
        [0.0513],
        [0.2066],
        [0.5374],
        [0.0059],
        [0.2224],
        [0.1254],
        [0.3754],
        [0.5258],
        [0.0939],
        [0.1778],
        [0.2772],
        [0.0344],
        [0.0388],
        [0.9426],
        [0.1209],
        [0.2947],
        [0.0870],
        [0.4037],
        [0.0158]])</code></pre>
</div>
</div>
<div id="cell-20" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a><span class="co"># Sample class labels</span></span>
<span id="cb13-2"><a href="#cb13-2"></a>Y <span class="op">=</span> torch.distributions.Bernoulli(prob_Y).sample()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-21" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a><span class="co"># Convert to NumPy for visualization</span></span>
<span id="cb14-2"><a href="#cb14-2"></a>X1_np, X2_np, Y_np <span class="op">=</span> X1.numpy(), X2.numpy(), Y.numpy()</span>
<span id="cb14-3"><a href="#cb14-3"></a></span>
<span id="cb14-4"><a href="#cb14-4"></a><span class="co"># Plot data points</span></span>
<span id="cb14-5"><a href="#cb14-5"></a>plt.scatter(X1_np[Y_np <span class="op">==</span> <span class="dv">0</span>], X2_np[Y_np <span class="op">==</span> <span class="dv">0</span>], color<span class="op">=</span><span class="st">"blue"</span>, label<span class="op">=</span><span class="st">"Class 0"</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb14-6"><a href="#cb14-6"></a>plt.scatter(X1_np[Y_np <span class="op">==</span> <span class="dv">1</span>], X2_np[Y_np <span class="op">==</span> <span class="dv">1</span>], color<span class="op">=</span><span class="st">"red"</span>, label<span class="op">=</span><span class="st">"Class 1"</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb14-7"><a href="#cb14-7"></a>plt.xlabel(<span class="st">"Feature 1 (X1)"</span>)</span>
<span id="cb14-8"><a href="#cb14-8"></a>plt.ylabel(<span class="st">"Feature 2 (X2)"</span>)</span>
<span id="cb14-9"><a href="#cb14-9"></a>plt.legend()</span>
<span id="cb14-10"><a href="#cb14-10"></a>plt.title(<span class="st">"Generated 2D Logistic Regression Data"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>Text(0.5, 1.0, 'Generated 2D Logistic Regression Data')</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="logistic-regression-generative_files/figure-html/cell-13-output-2.png" width="554" height="454" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-22" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb16-2"><a href="#cb16-2"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb16-3"><a href="#cb16-3"></a></span>
<span id="cb16-4"><a href="#cb16-4"></a><span class="co"># Stack X1 and X2 into a single tensor</span></span>
<span id="cb16-5"><a href="#cb16-5"></a>X_train <span class="op">=</span> torch.cat((X1, X2), dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-6"><a href="#cb16-6"></a></span>
<span id="cb16-7"><a href="#cb16-7"></a><span class="co"># Define logistic regression model</span></span>
<span id="cb16-8"><a href="#cb16-8"></a><span class="kw">class</span> LogisticRegression2D(nn.Module):</span>
<span id="cb16-9"><a href="#cb16-9"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb16-10"><a href="#cb16-10"></a>        <span class="bu">super</span>(LogisticRegression2D, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb16-11"><a href="#cb16-11"></a>        <span class="va">self</span>.linear <span class="op">=</span> nn.Linear(<span class="dv">2</span>, <span class="dv">1</span>)  <span class="co"># Two inputs, one output</span></span>
<span id="cb16-12"><a href="#cb16-12"></a></span>
<span id="cb16-13"><a href="#cb16-13"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb16-14"><a href="#cb16-14"></a>        <span class="cf">return</span> torch.sigmoid(<span class="va">self</span>.linear(x))  <span class="co"># Sigmoid activation</span></span>
<span id="cb16-15"><a href="#cb16-15"></a></span>
<span id="cb16-16"><a href="#cb16-16"></a><span class="co"># Initialize model</span></span>
<span id="cb16-17"><a href="#cb16-17"></a>model <span class="op">=</span> LogisticRegression2D()</span>
<span id="cb16-18"><a href="#cb16-18"></a>loss_fn <span class="op">=</span> nn.BCELoss()  <span class="co"># Binary cross-entropy loss</span></span>
<span id="cb16-19"><a href="#cb16-19"></a>optimizer <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb16-20"><a href="#cb16-20"></a></span>
<span id="cb16-21"><a href="#cb16-21"></a><span class="co"># Training loop</span></span>
<span id="cb16-22"><a href="#cb16-22"></a>epochs <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb16-23"><a href="#cb16-23"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb16-24"><a href="#cb16-24"></a>    optimizer.zero_grad()</span>
<span id="cb16-25"><a href="#cb16-25"></a>    Y_pred <span class="op">=</span> model(X_train)  <span class="co"># Forward pass</span></span>
<span id="cb16-26"><a href="#cb16-26"></a>    loss <span class="op">=</span> loss_fn(Y_pred, Y.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))  <span class="co"># Compute loss</span></span>
<span id="cb16-27"><a href="#cb16-27"></a>    loss.backward()  <span class="co"># Backpropagation</span></span>
<span id="cb16-28"><a href="#cb16-28"></a>    optimizer.step()  <span class="co"># Update weights</span></span>
<span id="cb16-29"><a href="#cb16-29"></a></span>
<span id="cb16-30"><a href="#cb16-30"></a>    <span class="cf">if</span> epoch <span class="op">%</span> <span class="dv">200</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb16-31"><a href="#cb16-31"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">, Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb16-32"><a href="#cb16-32"></a></span>
<span id="cb16-33"><a href="#cb16-33"></a><span class="co"># Extract learned parameters</span></span>
<span id="cb16-34"><a href="#cb16-34"></a>w1_learned, w2_learned <span class="op">=</span> model.linear.weight[<span class="dv">0</span>].detach().numpy()</span>
<span id="cb16-35"><a href="#cb16-35"></a>b_learned <span class="op">=</span> model.linear.bias[<span class="dv">0</span>].detach().numpy()</span>
<span id="cb16-36"><a href="#cb16-36"></a><span class="bu">print</span>(<span class="ss">f"Learned Parameters: w1 = </span><span class="sc">{</span>w1_learned<span class="sc">:.4f}</span><span class="ss">, w2 = </span><span class="sc">{</span>w2_learned<span class="sc">:.4f}</span><span class="ss">, b = </span><span class="sc">{</span>b_learned<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Epoch 0, Loss: 2.0864
Epoch 200, Loss: 0.4884
Epoch 400, Loss: 0.4536
Epoch 600, Loss: 0.4395
Epoch 800, Loss: 0.4318
Learned Parameters: w1 = 0.6339, w2 = -0.8716, b = -0.4170</code></pre>
</div>
</div>
<div id="cell-23" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a><span class="kw">def</span> plot_decision_boundary(model, X1_np, X2_np, Y_np, w1_true, w2_true, b_true):</span>
<span id="cb18-2"><a href="#cb18-2"></a>    <span class="co">"""Plots the true and learned decision boundaries."""</span></span>
<span id="cb18-3"><a href="#cb18-3"></a>    </span>
<span id="cb18-4"><a href="#cb18-4"></a>    <span class="co"># Generate mesh grid</span></span>
<span id="cb18-5"><a href="#cb18-5"></a>    x1_vals <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">100</span>)</span>
<span id="cb18-6"><a href="#cb18-6"></a>    x2_vals <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">100</span>)</span>
<span id="cb18-7"><a href="#cb18-7"></a>    X1_grid, X2_grid <span class="op">=</span> np.meshgrid(x1_vals, x2_vals)</span>
<span id="cb18-8"><a href="#cb18-8"></a></span>
<span id="cb18-9"><a href="#cb18-9"></a>    <span class="co"># Compute model's learned decision boundary</span></span>
<span id="cb18-10"><a href="#cb18-10"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb18-11"><a href="#cb18-11"></a>        Z <span class="op">=</span> model(torch.tensor(np.c_[X1_grid.ravel(), X2_grid.ravel()], dtype<span class="op">=</span>torch.float32))</span>
<span id="cb18-12"><a href="#cb18-12"></a>        Z <span class="op">=</span> Z.view(X1_grid.shape).numpy()</span>
<span id="cb18-13"><a href="#cb18-13"></a></span>
<span id="cb18-14"><a href="#cb18-14"></a>    <span class="co"># Compute true decision boundary</span></span>
<span id="cb18-15"><a href="#cb18-15"></a>    x1_boundary <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">5</span>, <span class="dv">100</span>)</span>
<span id="cb18-16"><a href="#cb18-16"></a>    x2_boundary_true <span class="op">=</span> <span class="op">-</span> (w1_true <span class="op">/</span> w2_true) <span class="op">*</span> x1_boundary <span class="op">-</span> (b_true <span class="op">/</span> w2_true)</span>
<span id="cb18-17"><a href="#cb18-17"></a></span>
<span id="cb18-18"><a href="#cb18-18"></a>    <span class="co"># Plot data points</span></span>
<span id="cb18-19"><a href="#cb18-19"></a>    plt.scatter(X1_np[Y_np <span class="op">==</span> <span class="dv">0</span>], X2_np[Y_np <span class="op">==</span> <span class="dv">0</span>], color<span class="op">=</span><span class="st">"blue"</span>, label<span class="op">=</span><span class="st">"Class 0"</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-20"><a href="#cb18-20"></a>    plt.scatter(X1_np[Y_np <span class="op">==</span> <span class="dv">1</span>], X2_np[Y_np <span class="op">==</span> <span class="dv">1</span>], color<span class="op">=</span><span class="st">"red"</span>, label<span class="op">=</span><span class="st">"Class 1"</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb18-21"><a href="#cb18-21"></a></span>
<span id="cb18-22"><a href="#cb18-22"></a>    <span class="co"># Plot learned decision boundary</span></span>
<span id="cb18-23"><a href="#cb18-23"></a>    plt.contour(X1_grid, X2_grid, Z, levels<span class="op">=</span>[<span class="fl">0.5</span>], colors<span class="op">=</span><span class="st">"black"</span>, linestyles<span class="op">=</span><span class="st">"dashed"</span>, label<span class="op">=</span><span class="st">"Learned Boundary"</span>)</span>
<span id="cb18-24"><a href="#cb18-24"></a></span>
<span id="cb18-25"><a href="#cb18-25"></a>    <span class="co"># Plot true decision boundary</span></span>
<span id="cb18-26"><a href="#cb18-26"></a>    plt.plot(x1_boundary, x2_boundary_true, color<span class="op">=</span><span class="st">"green"</span>, linestyle<span class="op">=</span><span class="st">"solid"</span>, label<span class="op">=</span><span class="st">"True Boundary"</span>)</span>
<span id="cb18-27"><a href="#cb18-27"></a></span>
<span id="cb18-28"><a href="#cb18-28"></a>    plt.xlabel(<span class="st">"Feature 1 (X1)"</span>)</span>
<span id="cb18-29"><a href="#cb18-29"></a>    plt.ylabel(<span class="st">"Feature 2 (X2)"</span>)</span>
<span id="cb18-30"><a href="#cb18-30"></a>    plt.legend()</span>
<span id="cb18-31"><a href="#cb18-31"></a>    plt.title(<span class="st">"Logistic Regression Decision Boundary"</span>)</span>
<span id="cb18-32"><a href="#cb18-32"></a>    plt.ylim([<span class="dv">0</span>, <span class="dv">5</span>])</span>
<span id="cb18-33"><a href="#cb18-33"></a></span>
<span id="cb18-34"><a href="#cb18-34"></a></span>
<span id="cb18-35"><a href="#cb18-35"></a><span class="co"># Call the function with true and learned parameters</span></span>
<span id="cb18-36"><a href="#cb18-36"></a>plot_decision_boundary(model, X1_np, X2_np, Y_np, w1_true<span class="op">=</span><span class="fl">1.2</span>, w2_true<span class="op">=-</span><span class="fl">0.8</span>, b_true<span class="op">=-</span><span class="fl">2.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="logistic-regression-generative_files/figure-html/cell-15-output-1.png" width="558" height="454" class="figure-img"></p>
</figure>
</div>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/nipunbatra\.github\.io\/psdv-teaching");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2024-2025, Prof.&nbsp;Nipun Batra, IIT Gandhinagar</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.dev/nipunbatra/psdv-teaching/blob/main/notebooks/logistic-regression-generative.ipynb" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/nipunbatra/psdv-teaching/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/nipunbatra/psdv-teaching">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://nipunbatra.github.io">
      <i class="bi bi-globe" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>